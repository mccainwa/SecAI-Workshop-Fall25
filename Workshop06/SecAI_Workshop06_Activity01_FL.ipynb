{"cells":[{"cell_type":"markdown","metadata":{"id":"2Cz-X5KBsu68"},"source":["# **Federated Learning with Differential Privacy**"]},{"cell_type":"markdown","metadata":{"id":"4rtvHDfqsu6_"},"source":["### **Case Study:**\n","\n","#### **1. Introduction to Federated Learning (FL)**\n","\n","Federated Learning (FL) is a machine learning technique that allows multiple decentralized devices (or clients) to collaboratively train a model without sharing raw data with each other or a central server. Instead of collecting all the data in a single place, the model is trained locally on each client, and only model updates (such as gradients) are shared with a central server. This decentralized learning process maintains data privacy, as no personal data is ever shared across devices.\n","\n","* **Client Model**: Each client, such as a mobile phone or IoT device, trains a local copy of the model using its private data. This local training process ensures the data remains on the client device.\n","\n","* **Server Model**: The central server aggregates the updates received from the clients to improve the global model. The server doesn't have access to the raw data, only the model updates.\n","\n","<div style=\"text-align: center;\">\n","    <img src=\"https://www.dailydoseofds.com/content/images/2023/11/federated-gif.gif\" alt=\"Epsilon Impact\" width=\"700\">\n","</div>\n","\n","#### **2. The Need for Privacy in Federated Learning**\n","\n","While federated learning provides a strong foundation for data privacy by not transmitting raw data, the model updates (gradients) exchanged between clients and the server can still reveal sensitive information. To mitigate this risk, Differential Privacy (DP) is applied to the model updates to ensure that individual data points cannot be identified or reconstructed from these updates.\n","\n","#### **3. Differential Privacy in Federated Learning**\n","\n","Differential Privacy (DP) is a privacy-enhancing technique designed to provide mathematical guarantees about the privacy of individual data points, even in the presence of aggregate data. DP introduces noise to the data or model updates in a way that ensures no individual’s data can be singled out, while still allowing the model to learn useful patterns.\n","\n","In the context of federated learning, differential privacy can be applied to:\n","\n","* **Local Updates**: Adding noise to the model updates before they are sent to the server.\n","* **Global Aggregation**: Adding noise to the aggregated updates on the server before they are used to update the global model.\n","\n","By introducing this noise, differential privacy helps ensure that the model updates do not reveal information about any individual client’s data.\n","\n","#### **4. Centralized Differential Privacy (CDP) vs. Local Differential Privacy (LDP)**\n","\n","There are two primary types of differential privacy that can be used in federated learning: Centralized Differential Privacy (CDP) and Local Differential Privacy (LDP).\n","\n","* **Centralized Differential Privacy (CDP)**: In this approach, noise is added to the model updates at the server level, after the clients have already sent their updates. CDP provides privacy guarantees for the aggregated data received from the clients. It is typically easier to implement since the server controls the noise addition process, but it does rely on the trustworthiness of the server.\n","\n","* **Local Differential Privacy (LDP)**: In contrast, LDP adds noise at the client level before the updates are sent to the server. This approach ensures that even the server cannot deduce any individual information from the updates. LDP provides stronger privacy guarantees, as the clients are directly responsible for their privacy, but it can introduce more noise, reducing the quality of the model updates.\n","\n","Both CDP and LDP are designed to provide robust privacy guarantees, but the choice between them depends on the desired balance between privacy and model accuracy.\n","\n","#### **5. Global Aggregation Methods in Federated Learning**\n","\n","Once the clients have trained their local models and potentially applied differential privacy, the server must aggregate these local updates into a global model. Several methods are used for global aggregation:\n","\n","* **Federated Averaging (FedAvg)**: This is the most common aggregation method in federated learning. It computes the weighted average of the model updates from all clients. The weight for each update is typically based on the amount of data on the client, ensuring that clients with more data contribute more to the global model.\n","\n","**Mathematical Concept:**\n","\n","Let’s assume there are $K$ clients. Each client $k$ trains a model locally using its own data and computes a model update $w_{k}$​ (which can represent the model parameters or the gradient updates) after local training. The server aggregates these local updates to form the global model wglobalwglobal​.\n","\n","Let:\n","\n","* $n_{k}​$: The number of data points on client $k$.\n","* $N$: The total number of data points across all clients (i.e., $N= \\sum_{k=1}^{K}n_{k}$​).\n","* $w_{k}$​: The model parameters after training on client k.\n","* $w_{global}$​: The global model parameters that the server computes after aggregation.\n","\n","The aggregation step in FedAvg is given by the weighted average:\n","$$w_{global}=\\frac{1}{N} \\sum_{k=1}^Kn_kw_k$$\n","\n","This ensures that clients with more data $(n_k)$ contribute more to the global model wglobalwglobal​. It reflects a natural weighting of the client models by the size of their respective datasets.\n","\n","* **Federated Stochastic Gradient Descent (FedSGD)**: In this method, the server aggregates the gradients directly instead of averaging the models. The gradients are sent by clients after they perform a local update, and the server uses these gradients to perform the global update.\n","\n","**Mathematical Concept:**\n","\n","Let:\n","\n","* $g_k$​ be the gradient of the loss function computed by client $k$.\n","* $g_{global}$​ be the aggregated gradient.\n","* $η$ be the learning rate.\n","* $w_{global}$​ be the global model parameters.\n","\n","Each client $k$ computes a gradient $g_k=∇f_k(w)$ based on its local loss function $f_k$​, where $w$ are the model parameters.\n","\n","At the server, the gradients from each client are aggregated by computing their average (or weighted average in some cases):\n","$$g_{global}=\\frac{1}{N} \\sum_{k=1}^Kn_kg_k$$\n","\n","where:\n","\n","* $n_k$​: The number of data points on client $k$.\n","* $N$: The total number of data points.\n","\n","The server then performs an update on the global model:\n","$$w_{global}^{t+1}=w_{global}^t−ηg_{global}$$\n","\n","\n","This update step allows the server to improve the global model based on the averaged gradients computed by the clients. Unlike FedAvg, which averages the model parameters, FedSGD directly updates the model using the gradient information.\n","\n","* **Secure Aggregation**: To enhance privacy, secure aggregation protocols can be used. This ensures that the server only sees the aggregated result, without being able to observe individual updates from clients, protecting the privacy of the model updates.\n","\n","**Mathematical Concept:**\n","\n","To achieve secure aggregation, the clients first apply encryption (such as additive homomorphic encryption) to their model updates before sending them to the server. The server can then aggregate the encrypted model updates without seeing the individual updates.\n","\n","Let's assume each client $k$ sends an encrypted update $\\hat{w}_{k}​$, where:\n","$$\\hat{w}_k=w_k+e_k$$\n","\n","Here, $e_k$​ is the encryption (noise) that hides the true model update $w_k$ from the server, and $\\hat{w}_k$​ is the noisy (encrypted) update that is sent to the server.\n","\n","The server only sees the sum of the encrypted updates:\n","$$\\hat{w}_{global}=\\sum_{k=1}^K\\hat{w}_k$$\n","\n","The key property of additive homomorphic encryption is that the server can compute the sum of the encrypted values:\n","$$\\hat{w}_{global}=\\sum_{k=1}^K(w_k+e_k)=\\sum_{k=1}^Kw_k+\\sum_{k=1}^Ke_k$$\n","\n","The server cannot see the individual updates $w_k$​, but it can still aggregate them to compute the global model update.\n","\n","To remove the noise, clients use a decryption key to decrypt their updates before sending them. This process ensures that only the sum of the updates is visible to the server, preserving client privacy.\n","\n","_____\n","\n","Federated Learning combined with Differential Privacy provides a powerful framework for privacy-preserving machine learning. By allowing clients to train models on their own data without sharing it and applying noise to the updates, federated learning ensures privacy while still enabling the creation of accurate global models. The choice between Centralized and Local Differential Privacy and the selection of global aggregation methods depend on the specific privacy and accuracy requirements of the application.\n","\n","In our case study, the implementation of FL with DP (either CDP or LDP) can serve as a foundation for understanding how privacy-preserving machine learning systems can be built, particularly in industries like healthcare, finance, or IoT, where data privacy is of utmost importance.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9123,"status":"ok","timestamp":1757607533744,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"aJy87upuw-fi","outputId":"a111bb24-9a7d-4ae8-944a-6531f657d5b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n","Requirement already satisfied: opacus in /usr/local/lib/python3.12/dist-packages (1.5.4)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.8.0+cu126)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.1)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"]}],"source":["!pip install torchmetrics\n","!pip install opacus"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1757607555722,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"9BCQEgUksu7D"},"outputs":[],"source":["import random\n","import copy\n","from datetime import date\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","from collections import OrderedDict\n","\n","import numpy as np\n","import torch\n","import torchmetrics\n","from torch import nn, tanh\n","from torch.nn.functional import relu, softmax, max_pool2d\n","\n","import torchvision.transforms as transforms\n","from torchvision.datasets import MNIST, FashionMNIST\n","\n","from collections import defaultdict\n","\n","import opacus\n","from opacus.validators import ModuleValidator\n","from opacus.utils.batch_memory_manager import BatchMemoryManager"]},{"cell_type":"markdown","metadata":{"id":"wC4efabEsu7E"},"source":["### Loading MNIST10 Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1757607902033,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"UfH2CSwAsu7G"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","DATA_NAME = 'mnist'\n","root = '~/torch_data'\n","NUM_CLIENTS = 50\n","BATCH_SIZE = 64\n","NUM_CLASSES = 10\n","NUM_CLASES_PER_CLIENT = 10\n","sample_rate = 1\n","\n","LEARNING_RATE_DIS = 2e-1\n","EPOCHS = 1\n","ROUNDS = 10\n","MODE = \"LDP\"\n","target_epsilon = 8\n","mp_bs = 64\n","target_delta = 1e-3\n","\n","user_param = {'disc_lr': LEARNING_RATE_DIS, 'epochs': EPOCHS}\n","user_param['rounds'] = ROUNDS\n","user_param['target_epsilon'] = target_epsilon\n","user_param['target_delta'] = target_delta\n","user_param['sr'] = sample_rate\n","user_param['mp_bs'] = mp_bs\n","\n","server_param = {}"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1757607907586,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"8GdOkewTsu7L"},"outputs":[],"source":["def get_datasets(data_name, dataroot, preprocess = None):\n","    if data_name == 'mnist':\n","        normalization = transforms.Normalize((0.5,), (0.5,))\n","        transform = transforms.Compose([transforms.ToTensor(), normalization])\n","        data_obj = MNIST\n","    elif data_name == 'fashionmnist':\n","        normalization = transforms.Normalize((0.5,), (0.5,))\n","        transform = transforms.Compose([transforms.ToTensor(),  normalization])\n","        data_obj = FashionMNIST\n","    else:\n","        raise ValueError(\"choose data_name from ['mnist', 'fashionmnist']\")\n","\n","\n","    train_set = data_obj(dataroot, train=True, transform=transform, download=True)\n","    test_set = data_obj(dataroot, train=False, transform=transform)\n","    return train_set, test_set"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1757608086870,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"U6liy3xzsu7L"},"outputs":[],"source":["def get_num_classes_samples(dataset):\n","    \"\"\"\n","    extracts info about certain dataset\n","    :param dataset: pytorch dataset object\n","    :return: dataset info number of classes, number of samples, list of labels\n","    \"\"\"\n","    # ---------------#\n","    # Extract labels #\n","    # ---------------#\n","    if isinstance(dataset, torch.utils.data.Subset):\n","        if isinstance(dataset.dataset.targets, list):\n","            data_labels_list = np.array(dataset.dataset.targets)[dataset.indices]\n","        else:\n","            data_labels_list = dataset.dataset.targets[dataset.indices]\n","    else:\n","        if isinstance(dataset.targets, list):\n","            data_labels_list = np.array(dataset.targets)\n","        else:\n","            data_labels_list = dataset.targets\n","    classes, num_samples = np.unique(data_labels_list, return_counts=True)\n","    num_classes = len(classes)\n","    return num_classes, num_samples, data_labels_list"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1757608090709,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"cLP9ZDOksu7M"},"outputs":[],"source":["def gen_classes_per_node(dataset, num_users, classes_per_user=2, high_prob=0.6, low_prob=0.4):\n","    \"\"\"\n","    creates the data distribution of each client\n","    :param dataset: pytorch dataset object\n","    :param num_users: number of clients\n","    :param classes_per_user: number of classes assigned to each client\n","    :param high_prob: highest prob sampled\n","    :param low_prob: lowest prob sampled\n","    :return: dictionary mapping between classes and proportions, each entry refers to other client\n","    \"\"\"\n","    num_classes, num_samples, _ = get_num_classes_samples(dataset)\n","\n","    # -------------------------------------------#\n","    # Divide classes + num samples for each user #\n","    # -------------------------------------------#\n","    # print(num_classes)\n","    assert (classes_per_user * num_users) % num_classes == 0, \"equal classes appearance is needed\"\n","    count_per_class = (classes_per_user * num_users) // num_classes\n","    class_dict = {}\n","    for i in range(num_classes):\n","        probs=np.array([1]*count_per_class)\n","        probs_norm = (probs / probs.sum()).tolist()\n","        class_dict[i] = {'count': count_per_class, 'prob': probs_norm}\n","    # -------------------------------------#\n","    # Assign each client with data indexes #\n","    # -------------------------------------#\n","    class_partitions = defaultdict(list)\n","    for i in range(num_users):\n","        c = []\n","        for _ in range(classes_per_user):\n","            class_counts = [class_dict[i]['count'] for i in range(num_classes)]\n","            max_class_counts = np.where(np.array(class_counts) == max(class_counts))[0]\n","            max_class_counts = np.setdiff1d(max_class_counts, np.array(c))\n","            c.append(np.random.choice(max_class_counts))\n","            class_dict[c[-1]]['count'] -= 1\n","        class_partitions['class'].append(c)\n","        class_partitions['prob'].append([class_dict[i]['prob'].pop() for i in c])\n","    return class_partitions"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1757608094890,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"ynF7PHu2su7P"},"outputs":[],"source":["def gen_data_split(dataset, num_users, class_partitions):\n","    \"\"\"\n","    divide data indexes for each client based on class_partition\n","    :param dataset: pytorch dataset object (train/val/test)\n","    :param num_users: number of clients\n","    :param class_partitions: proportion of classes per client\n","    :return: dictionary mapping client to its indexes\n","    \"\"\"\n","    num_classes, num_samples, data_labels_list = get_num_classes_samples(dataset)\n","\n","    # -------------------------- #\n","    # Create class index mapping #\n","    # -------------------------- #\n","    data_class_idx = {i: np.where(data_labels_list == i)[0] for i in range(num_classes)}\n","\n","    # --------- #\n","    # Shuffling #\n","    # --------- #\n","    for data_idx in data_class_idx.values():\n","        random.shuffle(data_idx)\n","\n","    # ------------------------------ #\n","    # Assigning samples to each user #\n","    # ------------------------------ #\n","    user_data_idx = [[] for i in range(num_users)]\n","    for usr_i in range(num_users):\n","        for c, p in zip(class_partitions['class'][usr_i], class_partitions['prob'][usr_i]):\n","            end_idx = int(num_samples[c] * p)\n","            user_data_idx[usr_i].extend(data_class_idx[c][:end_idx])\n","            data_class_idx[c] = data_class_idx[c][end_idx:]\n","        if len(user_data_idx[usr_i])%2 == 1: user_data_idx[usr_i] = user_data_idx[usr_i][:-1]\n","\n","    return user_data_idx"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1757608098151,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"GLe9MTvNsu7Q"},"outputs":[],"source":["def gen_random_loaders(data_name, data_path, num_users, bz, num_classes_per_user, num_classes, preprocess=None):\n","    \"\"\"\n","    generates train/val/test loaders of each client\n","    :param data_name: name of dataset, choose from [mnist10, fashionmnist, chmnist]\n","    :param data_path: root path for data dir\n","    :param num_users: number of clients\n","    :param bz: batch size\n","    :param classes_per_user: number of classes assigned to each client\n","    :return: train/val/test loaders of each client, list of pytorch dataloaders\n","    \"\"\"\n","    loader_params = {\"batch_size\": bz, \"shuffle\": False, \"pin_memory\": True, \"num_workers\": 0}\n","    dataloaders = []\n","    datasets = get_datasets(data_name, data_path, preprocess=preprocess)\n","    # print(datasets)\n","    cls_partitions = None\n","    distribution = np.zeros((num_users, num_classes))\n","    for i, d in enumerate(datasets):\n","        if i == 0:\n","            cls_partitions = gen_classes_per_node(d, num_users, num_classes_per_user)\n","            # print(cls_partitions)\n","            for index in range(num_users):\n","                distribution[index][cls_partitions['class'][index]] = cls_partitions['prob'][index]\n","\n","            loader_params['shuffle'] = True\n","        usr_subset_idx = gen_data_split(d, num_users, cls_partitions)\n","\n","        subsets = list(map(lambda x: torch.utils.data.Subset(d, x), usr_subset_idx))\n","        dataloaders.append(list(map(lambda x: torch.utils.data.DataLoader(x, **loader_params), subsets)))\n","\n","    return dataloaders"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4331,"status":"ok","timestamp":1757608142415,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"iCyVFQJGsu7S","outputId":"0f1093f8-dbf3-4f2b-d896-9f3eeb8d4b09"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 342kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 6.91MB/s]\n"]}],"source":["# we get the training data and test data for each user right now.\n","train_dataloaders, test_dataloaders  = gen_random_loaders(DATA_NAME, root, NUM_CLIENTS, BATCH_SIZE, NUM_CLASES_PER_CLIENT, NUM_CLASSES)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1757608153094,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"wjGZGXRc0a1B","outputId":"09ec9fc5-d293-4b13-ac9d-fad6e768d9ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50, 50)"]},"metadata":{},"execution_count":17}],"source":["len(train_dataloaders), len(test_dataloaders)"]},{"cell_type":"markdown","metadata":{"id":"jhXZPbfMsu7S"},"source":["### Save the training dataset and test dataset"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":15966,"status":"ok","timestamp":1757608557775,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"vqMLiGassu7S"},"outputs":[],"source":["def saveClientData(NUM_CLIENTS, dataset, folder_name, train = True):\n","\n","    if train:\n","        train = 'train'\n","    else:\n","        train = 'test'\n","\n","    for i in range(NUM_CLIENTS):\n","        data_directory = f'./{folder_name}/client_{train}_data'\n","        os.makedirs(data_directory, exist_ok = True)\n","\n","        user_batch_data = []\n","        user_batch_labels = []\n","        for img, lab in dataset[i]:\n","            user_batch_data.append(img)\n","            user_batch_labels.append(lab)\n","\n","        user_data_tensor = torch.cat(user_batch_data, dim=0)\n","        user_labels_tensor = torch.cat(user_batch_labels, dim=0)\n","\n","        # Save the concatenated data and labels to a single file\n","        torch.save({'images': user_data_tensor, 'labels': user_labels_tensor}, f'{data_directory}/client_{train}_{i:02}.pt')\n","\n","\n","def saveWeights(users, folder_name):\n","    weight_directory = f'./{folder_name}/client_model_weights'\n","    os.makedirs(weight_directory, exist_ok=True)\n","    for i in range(len(users)):\n","        # print('saving the weights of users:')\n","        torch.save(users[i].get_model_state_dict(), f\"{weight_directory}/weight_user{i:02}.pth\")\n","\n","def saveServerWeights(server, folder_name):\n","    model_directory = f'./{folder_name}/server_model_weights'\n","    os.makedirs(model_directory, exist_ok = True)\n","    torch.save(server.model.state_dict(), f\"{model_directory}/sever_model.pth\")\n","\n","\n","folder_name = 'FL_LDP_data'\n","saveClientData(NUM_CLIENTS, train_dataloaders, folder_name, train = True)\n","saveClientData(NUM_CLIENTS, test_dataloaders, folder_name, train = False)"]},{"cell_type":"markdown","metadata":{"id":"VpZtlS9psu7T"},"source":["## Building LDP User model"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1757608891834,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"ODzxcIwo1jVD","outputId":"21be20ef-2e0e-48bc-c4ce-9148ab0c8cdd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["784"]},"metadata":{},"execution_count":19}],"source":["28 * 28"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1757608981747,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"vRL6KrSEsu7T"},"outputs":[],"source":["# MODELS\n","class mnist_fully_connected(nn.Module):\n","    def __init__(self,num_classes):\n","        super(mnist_fully_connected, self).__init__()\n","        self.hidden1 = 600\n","        self.hidden2 = 100\n","        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n","        self.relu_ = nn.ReLU(inplace=False)\n","        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n","\n","    def forward(self,x, return_probs=True):\n","        x = x.view(-1, 28 * 28)\n","        x = self.relu_(self.fc1(x))\n","        x = relu(self.fc2(x))\n","        logits = self.fc3(x)\n","        if return_probs:\n","            return logits, softmax(logits, dim = 1)\n","        else:\n","            return logits\n"]},{"cell_type":"markdown","metadata":{"id":"NZ1QTZ97su7V"},"source":["## LDP CLIENT MODELS SETTINGS"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1757609645766,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"AdnNpQwGsu7W"},"outputs":[],"source":["class LDPUser:\n","    def __init__(self, index, device, model, n_classes, input_shape, train_dataloader, epochs, rounds,\n","                 target_epsilon, target_delta, sr, max_norm=2.0, disc_lr=5e-1, mp_bs = 3):\n","        self.index = index\n","        self.rounds = rounds\n","        self.target_epsilon = target_epsilon\n","        self.epsilon = 0\n","        self.delta = target_delta\n","        self.model = model(num_classes=n_classes)\n","        self.model = ModuleValidator.fix(self.model)\n","        self.train_dataloader = train_dataloader\n","        self.sr = sr\n","        self.mp_bs = mp_bs\n","        self.loss_fn = torch.nn.CrossEntropyLoss()\n","        self.disc_lr = disc_lr\n","        self.acc_metric = torchmetrics.Accuracy(task = 'multiclass', num_classes=10).to(device)\n","        self.device = device\n","        self.max_norm= max_norm\n","        self.epochs = epochs\n","        self.optim = torch.optim.SGD(self.model.parameters(), self.disc_lr)\n","        self.make_local_private()\n","\n","\n","\n","    def make_local_private(self):\n","        self.privacy_engine = opacus.PrivacyEngine()\n","        self.model, self.optim, self.train_dataloader = self.privacy_engine.make_private_with_epsilon(module=self.model, optimizer=self.optim,\n","                                                                                                      data_loader=self.train_dataloader, epochs=self.epochs*self.rounds*self.sr,\n","                                                                                                      target_epsilon=self.target_epsilon, target_delta=self.delta,\n","                                                                                                      max_grad_norm=self.max_norm)\n","\n","    def train(self):\n","        self.model = self.model.to(self.device)\n","        self.model.train()\n","        for epoch in range(self.epochs):\n","            with BatchMemoryManager(data_loader=self.train_dataloader, max_physical_batch_size=self.mp_bs, optimizer=self.optim) as batch_loader:\n","                for images, labels in batch_loader:\n","                    images, labels = images.to(self.device), labels.to(self.device)\n","                    self.optim.zero_grad()\n","                    logits, preds = self.model(images, return_probs=True)\n","                    loss = self.loss_fn(logits, labels)\n","                    loss.backward()\n","                    self.optim.step()\n","                    self.acc_metric(preds, labels)\n","        self.epsilon = self.privacy_engine.get_epsilon(self.delta)\n","        print(f\"Client: {self.index} ACC: {self.acc_metric.compute()}, episilon: {self.epsilon}\")\n","        self.acc_metric.reset()\n","        self.model.to('cpu')\n","\n","    def evaluate(self, dataloader):\n","        self.model.to(self.device)\n","        self.model.eval()\n","        testing_corrects = 0\n","        testing_sum = 0\n","        with torch.no_grad():\n","            for images, labels in dataloader:\n","                images, labels = images.to(self.device), labels.to(self.device)\n","                _, preds = self.model(images, return_probs=True)\n","                testing_corrects += torch.sum(torch.argmax(preds, dim=1) == labels)\n","                testing_sum += len(labels)\n","        self.model.to('cpu')\n","        return testing_corrects.cpu().detach().numpy(), testing_sum\n","\n","    def get_model_state_dict(self):\n","        return self.model.state_dict()\n","\n","    def set_model_state_dict(self, weights):\n","        for key, value in self.model.state_dict().items():\n","            if 'bn' not in key:\n","                self.model.state_dict()[key].data.copy_(weights[key])"]},{"cell_type":"markdown","metadata":{"id":"T73fNxfTsu7W"},"source":["## LDP SERVER MODEL SETTINGS"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1757609255313,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"MQo754imsu7W"},"outputs":[],"source":["class LDPServer:\n","    def __init__(self, device, model, n_classes, input_shape, noise_multiplier=1, sample_clients=10, disc_lr=1):\n","        self.model = model(num_classes=n_classes)\n","        self.model = ModuleValidator.fix(self.model)\n","        self.privacy_engine = opacus.PrivacyEngine()\n","        self.model = self.privacy_engine._prepare_model(self.model)\n","        self.device = device\n","        self.noise_multiplier = noise_multiplier\n","        self.sample_clients = sample_clients\n","        self.disc_lr = disc_lr\n","\n","    def get_model_state_dict(self):\n","        return self.model.state_dict()\n","\n","# Get the average weight of the client models.\n","def agg_weights(weights):\n","    with torch.no_grad():\n","        weights_avg = copy.deepcopy(weights[0])\n","        for k in weights_avg.keys():\n","            for i in range(1, len(weights)):\n","                weights_avg[k] += weights[i][k]\n","            weights_avg[k] = torch.div(weights_avg[k], len(weights))\n","    return weights_avg\n","\n","def evaluate_global(users, test_dataloders, users_index):\n","    testing_corrects = 0\n","    testing_sum = 0\n","    for index in users_index:\n","        corrects, num = users[index].evaluate(test_dataloders[index])\n","        testing_corrects += corrects\n","        testing_sum += num\n","    print(f\"Acc: {testing_corrects / testing_sum}\")\n","    return (testing_corrects / testing_sum)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":241438,"status":"ok","timestamp":1757609895709,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"dHY1VwJasu7W"},"outputs":[],"source":["user_obj = LDPUser\n","server_obj = LDPServer\n","MODEL = mnist_fully_connected\n","server_obj = LDPServer\n","server = server_obj(device, MODEL, NUM_CLASSES, None, **server_param)\n","users = [user_obj(i, device, MODEL, NUM_CLASSES, None, train_dataloaders[i], **user_param) for i in range(NUM_CLIENTS)]\n","\n","for i in range(NUM_CLIENTS):\n","    users[i].set_model_state_dict(server.get_model_state_dict())"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":386284,"status":"ok","timestamp":1757610305831,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"iatEZYFKsu7Y","outputId":"2df5aa85-8c16-480c-f95b-c5bba36f4c46"},"outputs":[{"output_type":"stream","name":"stderr","text":["sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Client: 11 ACC: 0.3101970851421356, episilon: 2.8713433066167053\n","Client: 21 ACC: 0.33497536182403564, episilon: 2.8713433066167053\n","Client: 8 ACC: 0.3559738099575043, episilon: 2.8713433066167053\n","Client: 22 ACC: 0.30844953656196594, episilon: 2.8713433066167053\n","Client: 18 ACC: 0.3378271162509918, episilon: 2.8713433066167053\n","Client: 36 ACC: 0.3316749632358551, episilon: 2.8713433066167053\n","Client: 0 ACC: 0.24567188322544098, episilon: 2.8713433066167053\n","Client: 31 ACC: 0.26655489206314087, episilon: 2.8713433066167053\n","Client: 17 ACC: 0.27241379022598267, episilon: 2.8713433066167053\n","Client: 37 ACC: 0.2880932688713074, episilon: 2.8713433066167053\n","Client: 44 ACC: 0.2820299565792084, episilon: 2.8713433066167053\n","Client: 25 ACC: 0.3563697040081024, episilon: 2.8713433066167053\n","Client: 9 ACC: 0.284246563911438, episilon: 2.8713433066167053\n","Client: 20 ACC: 0.29914531111717224, episilon: 2.8713433066167053\n","Client: 24 ACC: 0.31481480598449707, episilon: 2.8713433066167053\n","Client: 47 ACC: 0.3032855987548828, episilon: 2.8713433066167053\n","Client: 43 ACC: 0.33915212750434875, episilon: 2.8713433066167053\n","Client: 35 ACC: 0.30041152238845825, episilon: 2.8713433066167053\n","Client: 2 ACC: 0.3100000023841858, episilon: 2.8713433066167053\n","Client: 42 ACC: 0.34104540944099426, episilon: 2.8713433066167053\n","Client: 49 ACC: 0.29198312759399414, episilon: 2.8713433066167053\n","Client: 32 ACC: 0.3144286870956421, episilon: 2.8713433066167053\n","Client: 30 ACC: 0.25935596227645874, episilon: 2.8713433066167053\n","Client: 16 ACC: 0.31798437237739563, episilon: 2.8713433066167053\n","Client: 15 ACC: 0.2870216369628906, episilon: 2.8713433066167053\n","Client: 1 ACC: 0.3045685291290283, episilon: 2.8713433066167053\n","Client: 28 ACC: 0.27773213386535645, episilon: 2.8713433066167053\n","Client: 41 ACC: 0.25133216381073, episilon: 2.8713433066167053\n","Client: 27 ACC: 0.3213689625263214, episilon: 2.8713433066167053\n","Client: 13 ACC: 0.24092409014701843, episilon: 2.8713433066167053\n","Client: 6 ACC: 0.28260868787765503, episilon: 2.8713433066167053\n","Client: 5 ACC: 0.27078190445899963, episilon: 2.8713433066167053\n","Client: 4 ACC: 0.2764158844947815, episilon: 2.8713433066167053\n","Client: 39 ACC: 0.31693077087402344, episilon: 2.8713433066167053\n","Client: 19 ACC: 0.29450368881225586, episilon: 2.8713433066167053\n","Client: 10 ACC: 0.3227424621582031, episilon: 2.8713433066167053\n","Client: 29 ACC: 0.2616330087184906, episilon: 2.8713433066167053\n","Client: 34 ACC: 0.33252623677253723, episilon: 2.8713433066167053\n","Client: 7 ACC: 0.2805578410625458, episilon: 2.8713433066167053\n","Client: 12 ACC: 0.3290632367134094, episilon: 2.8713433066167053\n","Client: 40 ACC: 0.28138914704322815, episilon: 2.8713433066167053\n","Client: 46 ACC: 0.3166522979736328, episilon: 2.8713433066167053\n","Client: 33 ACC: 0.2707797884941101, episilon: 2.8713433066167053\n","Client: 26 ACC: 0.2897585332393646, episilon: 2.8713433066167053\n","Client: 14 ACC: 0.2954363524913788, episilon: 2.8713433066167053\n","Client: 3 ACC: 0.2961124777793884, episilon: 2.8713433066167053\n","Client: 48 ACC: 0.3030807673931122, episilon: 2.8713433066167053\n","Client: 45 ACC: 0.25205931067466736, episilon: 2.8713433066167053\n","Client: 38 ACC: 0.266505628824234, episilon: 2.8713433066167053\n","Client: 23 ACC: 0.2924070954322815, episilon: 2.8713433066167053\n","Round: 1\n","Acc: 0.5376288659793814\n","Epsilon: 2.8713433066167053\n","Client: 7 ACC: 0.5020145177841187, episilon: 3.7522789485121035\n","Client: 42 ACC: 0.5653287768363953, episilon: 3.7522789485121035\n","Client: 28 ACC: 0.4849267899990082, episilon: 3.7522789485121035\n","Client: 6 ACC: 0.5281749367713928, episilon: 3.7522789485121035\n","Client: 47 ACC: 0.5324786305427551, episilon: 3.7522789485121035\n","Client: 41 ACC: 0.5224913358688354, episilon: 3.7522789485121035\n","Client: 27 ACC: 0.5271785855293274, episilon: 3.7522789485121035\n","Client: 5 ACC: 0.5035211443901062, episilon: 3.7522789485121035\n","Client: 13 ACC: 0.555652916431427, episilon: 3.7522789485121035\n","Client: 40 ACC: 0.5102739930152893, episilon: 3.7522789485121035\n","Client: 48 ACC: 0.5272727012634277, episilon: 3.7522789485121035\n","Client: 8 ACC: 0.49620893597602844, episilon: 3.7522789485121035\n","Client: 12 ACC: 0.5058430433273315, episilon: 3.7522789485121035\n","Client: 29 ACC: 0.5280066132545471, episilon: 3.7522789485121035\n","Client: 46 ACC: 0.4932088255882263, episilon: 3.7522789485121035\n","Client: 38 ACC: 0.5135371088981628, episilon: 3.7522789485121035\n","Client: 10 ACC: 0.5103503465652466, episilon: 3.7522789485121035\n","Client: 1 ACC: 0.5655877590179443, episilon: 3.7522789485121035\n","Client: 32 ACC: 0.540885865688324, episilon: 3.7522789485121035\n","Client: 19 ACC: 0.5341196060180664, episilon: 3.7522789485121035\n","Client: 23 ACC: 0.5534383058547974, episilon: 3.7522789485121035\n","Client: 16 ACC: 0.5182879567146301, episilon: 3.7522789485121035\n","Client: 35 ACC: 0.5004359483718872, episilon: 3.7522789485121035\n","Client: 14 ACC: 0.5361595749855042, episilon: 3.7522789485121035\n","Client: 11 ACC: 0.4831560254096985, episilon: 3.7522789485121035\n","Client: 39 ACC: 0.5241730213165283, episilon: 3.7522789485121035\n","Client: 37 ACC: 0.51450514793396, episilon: 3.7522789485121035\n","Client: 36 ACC: 0.5222707390785217, episilon: 3.7522789485121035\n","Client: 24 ACC: 0.5061124563217163, episilon: 3.7522789485121035\n","Client: 45 ACC: 0.5269922614097595, episilon: 3.7522789485121035\n","Client: 34 ACC: 0.5101867318153381, episilon: 3.7522789485121035\n","Client: 15 ACC: 0.5, episilon: 3.7522789485121035\n","Client: 21 ACC: 0.5332252979278564, episilon: 3.7522789485121035\n","Client: 43 ACC: 0.4979149401187897, episilon: 3.7522789485121035\n","Client: 26 ACC: 0.5317829251289368, episilon: 3.7522789485121035\n","Client: 22 ACC: 0.5507881045341492, episilon: 3.7522789485121035\n","Client: 25 ACC: 0.4910790026187897, episilon: 3.7522789485121035\n","Client: 0 ACC: 0.5446127653121948, episilon: 3.7522789485121035\n","Client: 49 ACC: 0.5300084352493286, episilon: 3.7522789485121035\n","Client: 20 ACC: 0.5180520415306091, episilon: 3.7522789485121035\n","Client: 18 ACC: 0.4926108419895172, episilon: 3.7522789485121035\n","Client: 30 ACC: 0.5210016369819641, episilon: 3.7522789485121035\n","Client: 4 ACC: 0.5088967680931091, episilon: 3.7522789485121035\n","Client: 17 ACC: 0.5016920566558838, episilon: 3.7522789485121035\n","Client: 44 ACC: 0.5447019934654236, episilon: 3.7522789485121035\n","Client: 31 ACC: 0.49568966031074524, episilon: 3.7522789485121035\n","Client: 2 ACC: 0.53807532787323, episilon: 3.7522789485121035\n","Client: 9 ACC: 0.568728506565094, episilon: 3.7522789485121035\n","Client: 3 ACC: 0.5146805047988892, episilon: 3.7522789485121035\n","Client: 33 ACC: 0.5226510167121887, episilon: 3.7522789485121035\n","Round: 2\n","Acc: 0.667938144329897\n","Epsilon: 3.7522789485121035\n","Client: 23 ACC: 0.6134521961212158, episilon: 4.459352467409867\n","Client: 14 ACC: 0.6458157300949097, episilon: 4.459352467409867\n","Client: 34 ACC: 0.6045340299606323, episilon: 4.459352467409867\n","Client: 45 ACC: 0.6173912882804871, episilon: 4.459352467409867\n","Client: 27 ACC: 0.5901089906692505, episilon: 4.459352467409867\n","Client: 4 ACC: 0.5803418755531311, episilon: 4.459352467409867\n","Client: 26 ACC: 0.5887230634689331, episilon: 4.459352467409867\n","Client: 39 ACC: 0.5991631746292114, episilon: 4.459352467409867\n","Client: 46 ACC: 0.5922818779945374, episilon: 4.459352467409867\n","Client: 36 ACC: 0.6021329164505005, episilon: 4.459352467409867\n","Client: 11 ACC: 0.6329743266105652, episilon: 4.459352467409867\n","Client: 42 ACC: 0.6175496578216553, episilon: 4.459352467409867\n","Client: 1 ACC: 0.6023688912391663, episilon: 4.459352467409867\n","Client: 32 ACC: 0.5549828410148621, episilon: 4.459352467409867\n","Client: 41 ACC: 0.5904842615127563, episilon: 4.459352467409867\n","Client: 28 ACC: 0.6033613681793213, episilon: 4.459352467409867\n","Client: 35 ACC: 0.6044962406158447, episilon: 4.459352467409867\n","Client: 19 ACC: 0.5958677530288696, episilon: 4.459352467409867\n","Client: 16 ACC: 0.5824267864227295, episilon: 4.459352467409867\n","Client: 12 ACC: 0.5904590487480164, episilon: 4.459352467409867\n","Client: 15 ACC: 0.6214405298233032, episilon: 4.459352467409867\n","Client: 30 ACC: 0.6260364651679993, episilon: 4.459352467409867\n","Client: 0 ACC: 0.6326366662979126, episilon: 4.459352467409867\n","Client: 22 ACC: 0.603741466999054, episilon: 4.459352467409867\n","Client: 9 ACC: 0.6230706572532654, episilon: 4.459352467409867\n","Client: 43 ACC: 0.6226734519004822, episilon: 4.459352467409867\n","Client: 25 ACC: 0.6030150651931763, episilon: 4.459352467409867\n","Client: 37 ACC: 0.650542140007019, episilon: 4.459352467409867\n","Client: 48 ACC: 0.6064461469650269, episilon: 4.459352467409867\n","Client: 29 ACC: 0.5790795087814331, episilon: 4.459352467409867\n","Client: 17 ACC: 0.5948553085327148, episilon: 4.459352467409867\n","Client: 47 ACC: 0.6132780313491821, episilon: 4.459352467409867\n","Client: 2 ACC: 0.6077253222465515, episilon: 4.459352467409867\n","Client: 8 ACC: 0.6036789417266846, episilon: 4.459352467409867\n","Client: 7 ACC: 0.6338028311729431, episilon: 4.459352467409867\n","Client: 24 ACC: 0.625420868396759, episilon: 4.459352467409867\n","Client: 5 ACC: 0.6069691777229309, episilon: 4.459352467409867\n","Client: 31 ACC: 0.6045724153518677, episilon: 4.459352467409867\n","Client: 21 ACC: 0.6252045631408691, episilon: 4.459352467409867\n","Client: 6 ACC: 0.5785191059112549, episilon: 4.459352467409867\n","Client: 40 ACC: 0.5889520645141602, episilon: 4.459352467409867\n","Client: 18 ACC: 0.6344359517097473, episilon: 4.459352467409867\n","Client: 44 ACC: 0.6304888129234314, episilon: 4.459352467409867\n","Client: 49 ACC: 0.6097777485847473, episilon: 4.459352467409867\n","Client: 38 ACC: 0.563758373260498, episilon: 4.459352467409867\n","Client: 10 ACC: 0.6133333444595337, episilon: 4.459352467409867\n","Client: 13 ACC: 0.6181520819664001, episilon: 4.459352467409867\n","Client: 33 ACC: 0.5821635127067566, episilon: 4.459352467409867\n","Client: 3 ACC: 0.6564885377883911, episilon: 4.459352467409867\n","Client: 20 ACC: 0.5973488092422485, episilon: 4.459352467409867\n","Round: 3\n","Acc: 0.6802061855670103\n","Epsilon: 4.459352467409867\n","Client: 19 ACC: 0.6752356290817261, episilon: 5.07768292180549\n","Client: 38 ACC: 0.6386623382568359, episilon: 5.07768292180549\n","Client: 4 ACC: 0.6322795152664185, episilon: 5.07768292180549\n","Client: 8 ACC: 0.649754524230957, episilon: 5.07768292180549\n","Client: 29 ACC: 0.6320754885673523, episilon: 5.07768292180549\n","Client: 34 ACC: 0.6302040815353394, episilon: 5.07768292180549\n","Client: 49 ACC: 0.6310432553291321, episilon: 5.07768292180549\n","Client: 28 ACC: 0.6591695547103882, episilon: 5.07768292180549\n","Client: 7 ACC: 0.6760315895080566, episilon: 5.07768292180549\n","Client: 9 ACC: 0.6624578833580017, episilon: 5.07768292180549\n","Client: 6 ACC: 0.6409597396850586, episilon: 5.07768292180549\n","Client: 22 ACC: 0.6566523313522339, episilon: 5.07768292180549\n","Client: 39 ACC: 0.6435958743095398, episilon: 5.07768292180549\n","Client: 47 ACC: 0.6661101579666138, episilon: 5.07768292180549\n","Client: 31 ACC: 0.6579804420471191, episilon: 5.07768292180549\n","Client: 13 ACC: 0.6802074313163757, episilon: 5.07768292180549\n","Client: 45 ACC: 0.6374598145484924, episilon: 5.07768292180549\n","Client: 46 ACC: 0.6608419418334961, episilon: 5.07768292180549\n","Client: 10 ACC: 0.6663843989372253, episilon: 5.07768292180549\n","Client: 43 ACC: 0.6710758209228516, episilon: 5.07768292180549\n","Client: 15 ACC: 0.6738768815994263, episilon: 5.07768292180549\n","Client: 27 ACC: 0.6198830604553223, episilon: 5.07768292180549\n","Client: 2 ACC: 0.6616871953010559, episilon: 5.07768292180549\n","Client: 25 ACC: 0.6189300417900085, episilon: 5.07768292180549\n","Client: 14 ACC: 0.6786611080169678, episilon: 5.07768292180549\n","Client: 0 ACC: 0.6503856182098389, episilon: 5.07768292180549\n","Client: 26 ACC: 0.646766185760498, episilon: 5.07768292180549\n","Client: 11 ACC: 0.6784511804580688, episilon: 5.07768292180549\n","Client: 44 ACC: 0.6564885377883911, episilon: 5.07768292180549\n","Client: 3 ACC: 0.6504273414611816, episilon: 5.07768292180549\n","Client: 36 ACC: 0.6600000262260437, episilon: 5.07768292180549\n","Client: 20 ACC: 0.6456758975982666, episilon: 5.07768292180549\n","Client: 18 ACC: 0.6526225209236145, episilon: 5.07768292180549\n","Client: 32 ACC: 0.6355140209197998, episilon: 5.07768292180549\n","Client: 16 ACC: 0.6420722007751465, episilon: 5.07768292180549\n","Client: 48 ACC: 0.6456692814826965, episilon: 5.07768292180549\n","Client: 17 ACC: 0.6331456303596497, episilon: 5.07768292180549\n","Client: 35 ACC: 0.676495373249054, episilon: 5.07768292180549\n","Client: 42 ACC: 0.656985878944397, episilon: 5.07768292180549\n","Client: 21 ACC: 0.6686903834342957, episilon: 5.07768292180549\n","Client: 12 ACC: 0.6372630000114441, episilon: 5.07768292180549\n","Client: 30 ACC: 0.6647157073020935, episilon: 5.07768292180549\n","Client: 23 ACC: 0.6644628047943115, episilon: 5.07768292180549\n","Client: 37 ACC: 0.6565743684768677, episilon: 5.07768292180549\n","Client: 1 ACC: 0.6598579287528992, episilon: 5.07768292180549\n","Client: 33 ACC: 0.6405063271522522, episilon: 5.07768292180549\n","Client: 24 ACC: 0.6556122303009033, episilon: 5.07768292180549\n","Client: 41 ACC: 0.6552013158798218, episilon: 5.07768292180549\n","Client: 5 ACC: 0.632027268409729, episilon: 5.07768292180549\n","Client: 40 ACC: 0.6605042219161987, episilon: 5.07768292180549\n","Round: 4\n","Acc: 0.6990721649484536\n","Epsilon: 5.07768292180549\n","Client: 12 ACC: 0.6868600845336914, episilon: 5.639486891351173\n","Client: 26 ACC: 0.6601467132568359, episilon: 5.639486891351173\n","Client: 25 ACC: 0.6686440706253052, episilon: 5.639486891351173\n","Client: 0 ACC: 0.7265625, episilon: 5.639486891351173\n","Client: 5 ACC: 0.6765649914741516, episilon: 5.639486891351173\n","Client: 11 ACC: 0.6695278882980347, episilon: 5.639486891351173\n","Client: 15 ACC: 0.6978476643562317, episilon: 5.639486891351173\n","Client: 41 ACC: 0.6753670573234558, episilon: 5.639486891351173\n","Client: 19 ACC: 0.6892797350883484, episilon: 5.639486891351173\n","Client: 38 ACC: 0.6814236044883728, episilon: 5.639486891351173\n","Client: 47 ACC: 0.695246160030365, episilon: 5.639486891351173\n","Client: 18 ACC: 0.6647009253501892, episilon: 5.639486891351173\n","Client: 37 ACC: 0.7122483253479004, episilon: 5.639486891351173\n","Client: 33 ACC: 0.6397058963775635, episilon: 5.639486891351173\n","Client: 45 ACC: 0.6838656663894653, episilon: 5.639486891351173\n","Client: 44 ACC: 0.6936790943145752, episilon: 5.639486891351173\n","Client: 28 ACC: 0.6851098537445068, episilon: 5.639486891351173\n","Client: 27 ACC: 0.680134654045105, episilon: 5.639486891351173\n","Client: 7 ACC: 0.6997318863868713, episilon: 5.639486891351173\n","Client: 22 ACC: 0.6815999746322632, episilon: 5.639486891351173\n","Client: 6 ACC: 0.677880585193634, episilon: 5.639486891351173\n","Client: 4 ACC: 0.6755407452583313, episilon: 5.639486891351173\n","Client: 48 ACC: 0.6919233798980713, episilon: 5.639486891351173\n","Client: 39 ACC: 0.6645718812942505, episilon: 5.639486891351173\n","Client: 21 ACC: 0.6755852699279785, episilon: 5.639486891351173\n","Client: 34 ACC: 0.6888889074325562, episilon: 5.639486891351173\n","Client: 8 ACC: 0.6666666865348816, episilon: 5.639486891351173\n","Client: 40 ACC: 0.6962727904319763, episilon: 5.639486891351173\n","Client: 10 ACC: 0.692497968673706, episilon: 5.639486891351173\n","Client: 1 ACC: 0.6974652409553528, episilon: 5.639486891351173\n","Client: 31 ACC: 0.698825478553772, episilon: 5.639486891351173\n","Client: 49 ACC: 0.6876046657562256, episilon: 5.639486891351173\n","Client: 29 ACC: 0.6655791401863098, episilon: 5.639486891351173\n","Client: 35 ACC: 0.6791666746139526, episilon: 5.639486891351173\n","Client: 14 ACC: 0.6888889074325562, episilon: 5.639486891351173\n","Client: 42 ACC: 0.6727727055549622, episilon: 5.639486891351173\n","Client: 36 ACC: 0.6866554021835327, episilon: 5.639486891351173\n","Client: 24 ACC: 0.6608767509460449, episilon: 5.639486891351173\n","Client: 46 ACC: 0.7081993818283081, episilon: 5.639486891351173\n","Client: 2 ACC: 0.6699187159538269, episilon: 5.639486891351173\n","Client: 9 ACC: 0.6876533031463623, episilon: 5.639486891351173\n","Client: 13 ACC: 0.694957971572876, episilon: 5.639486891351173\n","Client: 23 ACC: 0.680672287940979, episilon: 5.639486891351173\n","Client: 30 ACC: 0.6962699890136719, episilon: 5.639486891351173\n","Client: 20 ACC: 0.6971946954727173, episilon: 5.639486891351173\n","Client: 32 ACC: 0.6985482573509216, episilon: 5.639486891351173\n","Client: 16 ACC: 0.6762767434120178, episilon: 5.639486891351173\n","Client: 3 ACC: 0.6996015906333923, episilon: 5.639486891351173\n","Client: 43 ACC: 0.6889795660972595, episilon: 5.639486891351173\n","Client: 17 ACC: 0.6735395193099976, episilon: 5.639486891351173\n","Round: 5\n","Acc: 0.718659793814433\n","Epsilon: 5.639486891351173\n","Client: 30 ACC: 0.7092731595039368, episilon: 6.16118965147976\n","Client: 22 ACC: 0.7035472989082336, episilon: 6.16118965147976\n","Client: 1 ACC: 0.6973018646240234, episilon: 6.16118965147976\n","Client: 26 ACC: 0.7189542651176453, episilon: 6.16118965147976\n","Client: 32 ACC: 0.7004328966140747, episilon: 6.16118965147976\n","Client: 47 ACC: 0.7156626582145691, episilon: 6.16118965147976\n","Client: 37 ACC: 0.7180805206298828, episilon: 6.16118965147976\n","Client: 36 ACC: 0.7266775965690613, episilon: 6.16118965147976\n","Client: 39 ACC: 0.7229729890823364, episilon: 6.16118965147976\n","Client: 10 ACC: 0.7204757928848267, episilon: 6.16118965147976\n","Client: 4 ACC: 0.7010398507118225, episilon: 6.16118965147976\n","Client: 17 ACC: 0.7050730586051941, episilon: 6.16118965147976\n","Client: 27 ACC: 0.7138184905052185, episilon: 6.16118965147976\n","Client: 3 ACC: 0.7146302461624146, episilon: 6.16118965147976\n","Client: 14 ACC: 0.7212543487548828, episilon: 6.16118965147976\n","Client: 11 ACC: 0.727120041847229, episilon: 6.16118965147976\n","Client: 2 ACC: 0.6993299722671509, episilon: 6.16118965147976\n","Client: 24 ACC: 0.734208345413208, episilon: 6.16118965147976\n","Client: 34 ACC: 0.6966666579246521, episilon: 6.16118965147976\n","Client: 44 ACC: 0.7040983438491821, episilon: 6.16118965147976\n","Client: 48 ACC: 0.6993243098258972, episilon: 6.16118965147976\n","Client: 7 ACC: 0.7014297842979431, episilon: 6.16118965147976\n","Client: 49 ACC: 0.7021452188491821, episilon: 6.16118965147976\n","Client: 23 ACC: 0.7208258509635925, episilon: 6.16118965147976\n","Client: 6 ACC: 0.7088716626167297, episilon: 6.16118965147976\n","Client: 0 ACC: 0.7278334498405457, episilon: 6.16118965147976\n","Client: 9 ACC: 0.7257093787193298, episilon: 6.16118965147976\n","Client: 42 ACC: 0.7160392999649048, episilon: 6.16118965147976\n","Client: 13 ACC: 0.71529620885849, episilon: 6.16118965147976\n","Client: 12 ACC: 0.6917293071746826, episilon: 6.16118965147976\n","Client: 29 ACC: 0.6705297827720642, episilon: 6.16118965147976\n","Client: 28 ACC: 0.7261512875556946, episilon: 6.16118965147976\n","Client: 15 ACC: 0.7169973850250244, episilon: 6.16118965147976\n","Client: 40 ACC: 0.7244157791137695, episilon: 6.16118965147976\n","Client: 35 ACC: 0.7305141091346741, episilon: 6.16118965147976\n","Client: 43 ACC: 0.7099359035491943, episilon: 6.16118965147976\n","Client: 21 ACC: 0.7242869734764099, episilon: 6.16118965147976\n","Client: 46 ACC: 0.7179916501045227, episilon: 6.16118965147976\n","Client: 33 ACC: 0.7027477025985718, episilon: 6.16118965147976\n","Client: 45 ACC: 0.6952539682388306, episilon: 6.16118965147976\n","Client: 8 ACC: 0.7079867124557495, episilon: 6.16118965147976\n","Client: 31 ACC: 0.7098401784896851, episilon: 6.16118965147976\n","Client: 16 ACC: 0.688814103603363, episilon: 6.16118965147976\n","Client: 38 ACC: 0.7207737565040588, episilon: 6.16118965147976\n","Client: 5 ACC: 0.7134404182434082, episilon: 6.16118965147976\n","Client: 25 ACC: 0.7227805852890015, episilon: 6.16118965147976\n","Client: 18 ACC: 0.6841216087341309, episilon: 6.16118965147976\n","Client: 41 ACC: 0.6992664933204651, episilon: 6.16118965147976\n","Client: 20 ACC: 0.685215950012207, episilon: 6.16118965147976\n","Client: 19 ACC: 0.7228306531906128, episilon: 6.16118965147976\n","Round: 6\n","Acc: 0.750618556701031\n","Epsilon: 6.16118965147976\n","Client: 39 ACC: 0.7225913405418396, episilon: 6.652517084761882\n","Client: 49 ACC: 0.7230639457702637, episilon: 6.652517084761882\n","Client: 13 ACC: 0.7377471923828125, episilon: 6.652517084761882\n","Client: 47 ACC: 0.743953287601471, episilon: 6.652517084761882\n","Client: 1 ACC: 0.7374392151832581, episilon: 6.652517084761882\n","Client: 48 ACC: 0.7565957307815552, episilon: 6.652517084761882\n","Client: 3 ACC: 0.7311657667160034, episilon: 6.652517084761882\n","Client: 40 ACC: 0.7266010046005249, episilon: 6.652517084761882\n","Client: 35 ACC: 0.746122419834137, episilon: 6.652517084761882\n","Client: 46 ACC: 0.7550854086875916, episilon: 6.652517084761882\n","Client: 17 ACC: 0.7299911975860596, episilon: 6.652517084761882\n","Client: 9 ACC: 0.7568027377128601, episilon: 6.652517084761882\n","Client: 25 ACC: 0.7344434857368469, episilon: 6.652517084761882\n","Client: 29 ACC: 0.7331649661064148, episilon: 6.652517084761882\n","Client: 45 ACC: 0.7247474789619446, episilon: 6.652517084761882\n","Client: 38 ACC: 0.723150372505188, episilon: 6.652517084761882\n","Client: 19 ACC: 0.7628259062767029, episilon: 6.652517084761882\n","Client: 5 ACC: 0.7374551892280579, episilon: 6.652517084761882\n","Client: 44 ACC: 0.7423469424247742, episilon: 6.652517084761882\n","Client: 37 ACC: 0.7323718070983887, episilon: 6.652517084761882\n","Client: 6 ACC: 0.7301587462425232, episilon: 6.652517084761882\n","Client: 32 ACC: 0.7341136932373047, episilon: 6.652517084761882\n","Client: 22 ACC: 0.7218044996261597, episilon: 6.652517084761882\n","Client: 41 ACC: 0.7514693737030029, episilon: 6.652517084761882\n","Client: 26 ACC: 0.7585345506668091, episilon: 6.652517084761882\n","Client: 10 ACC: 0.7317666411399841, episilon: 6.652517084761882\n","Client: 7 ACC: 0.7427843809127808, episilon: 6.652517084761882\n","Client: 21 ACC: 0.7547169923782349, episilon: 6.652517084761882\n","Client: 15 ACC: 0.7628259062767029, episilon: 6.652517084761882\n","Client: 4 ACC: 0.7321724891662598, episilon: 6.652517084761882\n","Client: 0 ACC: 0.760669469833374, episilon: 6.652517084761882\n","Client: 28 ACC: 0.7301324605941772, episilon: 6.652517084761882\n","Client: 14 ACC: 0.7318070530891418, episilon: 6.652517084761882\n","Client: 31 ACC: 0.717277467250824, episilon: 6.652517084761882\n","Client: 36 ACC: 0.7667473554611206, episilon: 6.652517084761882\n","Client: 23 ACC: 0.7763819098472595, episilon: 6.652517084761882\n","Client: 34 ACC: 0.7881856560707092, episilon: 6.652517084761882\n","Client: 20 ACC: 0.7267392873764038, episilon: 6.652517084761882\n","Client: 24 ACC: 0.7546531558036804, episilon: 6.652517084761882\n","Client: 27 ACC: 0.7252100706100464, episilon: 6.652517084761882\n","Client: 16 ACC: 0.7281385064125061, episilon: 6.652517084761882\n","Client: 42 ACC: 0.7536348700523376, episilon: 6.652517084761882\n","Client: 12 ACC: 0.7394603490829468, episilon: 6.652517084761882\n","Client: 8 ACC: 0.7380372881889343, episilon: 6.652517084761882\n","Client: 2 ACC: 0.7367563247680664, episilon: 6.652517084761882\n","Client: 33 ACC: 0.7336642146110535, episilon: 6.652517084761882\n","Client: 30 ACC: 0.7638190984725952, episilon: 6.652517084761882\n","Client: 11 ACC: 0.7453083395957947, episilon: 6.652517084761882\n","Client: 18 ACC: 0.7632450461387634, episilon: 6.652517084761882\n","Client: 43 ACC: 0.761904776096344, episilon: 6.652517084761882\n","Round: 7\n","Acc: 0.754020618556701\n","Epsilon: 6.652517084761882\n","Client: 49 ACC: 0.764950156211853, episilon: 7.119791580909087\n","Client: 28 ACC: 0.7702817916870117, episilon: 7.119791580909087\n","Client: 38 ACC: 0.7584124207496643, episilon: 7.119791580909087\n","Client: 46 ACC: 0.7753686308860779, episilon: 7.119791580909087\n","Client: 19 ACC: 0.7456067204475403, episilon: 7.119791580909087\n","Client: 25 ACC: 0.7546218633651733, episilon: 7.119791580909087\n","Client: 36 ACC: 0.7661430835723877, episilon: 7.119791580909087\n","Client: 37 ACC: 0.7667813897132874, episilon: 7.119791580909087\n","Client: 34 ACC: 0.7734242081642151, episilon: 7.119791580909087\n","Client: 42 ACC: 0.7573052048683167, episilon: 7.119791580909087\n","Client: 16 ACC: 0.7440719604492188, episilon: 7.119791580909087\n","Client: 20 ACC: 0.7542441487312317, episilon: 7.119791580909087\n","Client: 40 ACC: 0.7699999809265137, episilon: 7.119791580909087\n","Client: 5 ACC: 0.7430962324142456, episilon: 7.119791580909087\n","Client: 17 ACC: 0.7554076313972473, episilon: 7.119791580909087\n","Client: 23 ACC: 0.7617800831794739, episilon: 7.119791580909087\n","Client: 14 ACC: 0.7461273670196533, episilon: 7.119791580909087\n","Client: 10 ACC: 0.7615131735801697, episilon: 7.119791580909087\n","Client: 48 ACC: 0.7760459184646606, episilon: 7.119791580909087\n","Client: 45 ACC: 0.7179916501045227, episilon: 7.119791580909087\n","Client: 41 ACC: 0.7736318111419678, episilon: 7.119791580909087\n","Client: 24 ACC: 0.75611811876297, episilon: 7.119791580909087\n","Client: 11 ACC: 0.7518860101699829, episilon: 7.119791580909087\n","Client: 26 ACC: 0.7620252966880798, episilon: 7.119791580909087\n","Client: 39 ACC: 0.7426408529281616, episilon: 7.119791580909087\n","Client: 18 ACC: 0.7682926654815674, episilon: 7.119791580909087\n","Client: 27 ACC: 0.7271952033042908, episilon: 7.119791580909087\n","Client: 21 ACC: 0.7689741253852844, episilon: 7.119791580909087\n","Client: 1 ACC: 0.7891513705253601, episilon: 7.119791580909087\n","Client: 6 ACC: 0.7400844097137451, episilon: 7.119791580909087\n","Client: 22 ACC: 0.7491776347160339, episilon: 7.119791580909087\n","Client: 13 ACC: 0.7744932174682617, episilon: 7.119791580909087\n","Client: 29 ACC: 0.7514498829841614, episilon: 7.119791580909087\n","Client: 2 ACC: 0.7493517994880676, episilon: 7.119791580909087\n","Client: 7 ACC: 0.7809128761291504, episilon: 7.119791580909087\n","Client: 12 ACC: 0.7677199244499207, episilon: 7.119791580909087\n","Client: 0 ACC: 0.7644557952880859, episilon: 7.119791580909087\n","Client: 3 ACC: 0.7682291865348816, episilon: 7.119791580909087\n","Client: 35 ACC: 0.7807999849319458, episilon: 7.119791580909087\n","Client: 47 ACC: 0.7575236558914185, episilon: 7.119791580909087\n","Client: 9 ACC: 0.7819191217422485, episilon: 7.119791580909087\n","Client: 15 ACC: 0.7768860459327698, episilon: 7.119791580909087\n","Client: 31 ACC: 0.7466561794281006, episilon: 7.119791580909087\n","Client: 30 ACC: 0.7678571343421936, episilon: 7.119791580909087\n","Client: 33 ACC: 0.7630718946456909, episilon: 7.119791580909087\n","Client: 8 ACC: 0.760364830493927, episilon: 7.119791580909087\n","Client: 4 ACC: 0.7221742868423462, episilon: 7.119791580909087\n","Client: 32 ACC: 0.7739782929420471, episilon: 7.119791580909087\n","Client: 44 ACC: 0.7672268748283386, episilon: 7.119791580909087\n","Client: 43 ACC: 0.7687074542045593, episilon: 7.119791580909087\n","Round: 8\n","Acc: 0.7836082474226804\n","Epsilon: 7.119791580909087\n","Client: 16 ACC: 0.7560166120529175, episilon: 7.567398876139021\n","Client: 17 ACC: 0.7828894257545471, episilon: 7.567398876139021\n","Client: 5 ACC: 0.7698209881782532, episilon: 7.567398876139021\n","Client: 8 ACC: 0.7633779048919678, episilon: 7.567398876139021\n","Client: 28 ACC: 0.7947669625282288, episilon: 7.567398876139021\n","Client: 43 ACC: 0.7803855538368225, episilon: 7.567398876139021\n","Client: 46 ACC: 0.7813267707824707, episilon: 7.567398876139021\n","Client: 29 ACC: 0.7350286841392517, episilon: 7.567398876139021\n","Client: 9 ACC: 0.785653293132782, episilon: 7.567398876139021\n","Client: 40 ACC: 0.7766830921173096, episilon: 7.567398876139021\n","Client: 47 ACC: 0.785315215587616, episilon: 7.567398876139021\n","Client: 25 ACC: 0.7865546345710754, episilon: 7.567398876139021\n","Client: 1 ACC: 0.8041322231292725, episilon: 7.567398876139021\n","Client: 27 ACC: 0.7555012106895447, episilon: 7.567398876139021\n","Client: 2 ACC: 0.7769296169281006, episilon: 7.567398876139021\n","Client: 42 ACC: 0.7789566516876221, episilon: 7.567398876139021\n","Client: 21 ACC: 0.7809680104255676, episilon: 7.567398876139021\n","Client: 11 ACC: 0.7688442468643188, episilon: 7.567398876139021\n","Client: 30 ACC: 0.7562445998191833, episilon: 7.567398876139021\n","Client: 23 ACC: 0.8161582946777344, episilon: 7.567398876139021\n","Client: 32 ACC: 0.8051947951316833, episilon: 7.567398876139021\n","Client: 15 ACC: 0.7989690899848938, episilon: 7.567398876139021\n","Client: 12 ACC: 0.7833052277565002, episilon: 7.567398876139021\n","Client: 24 ACC: 0.7733563780784607, episilon: 7.567398876139021\n","Client: 31 ACC: 0.7752808928489685, episilon: 7.567398876139021\n","Client: 37 ACC: 0.7784184217453003, episilon: 7.567398876139021\n","Client: 34 ACC: 0.7887205481529236, episilon: 7.567398876139021\n","Client: 38 ACC: 0.7600685358047485, episilon: 7.567398876139021\n","Client: 10 ACC: 0.7988410592079163, episilon: 7.567398876139021\n","Client: 44 ACC: 0.7701342105865479, episilon: 7.567398876139021\n","Client: 20 ACC: 0.7983263731002808, episilon: 7.567398876139021\n","Client: 4 ACC: 0.7676420211791992, episilon: 7.567398876139021\n","Client: 49 ACC: 0.7806122303009033, episilon: 7.567398876139021\n","Client: 48 ACC: 0.7704213261604309, episilon: 7.567398876139021\n","Client: 19 ACC: 0.7722943425178528, episilon: 7.567398876139021\n","Client: 45 ACC: 0.7664233446121216, episilon: 7.567398876139021\n","Client: 22 ACC: 0.784928023815155, episilon: 7.567398876139021\n","Client: 33 ACC: 0.7680412530899048, episilon: 7.567398876139021\n","Client: 26 ACC: 0.8048986196517944, episilon: 7.567398876139021\n","Client: 35 ACC: 0.8117647171020508, episilon: 7.567398876139021\n","Client: 3 ACC: 0.7720465660095215, episilon: 7.567398876139021\n","Client: 18 ACC: 0.7860780954360962, episilon: 7.567398876139021\n","Client: 0 ACC: 0.792991042137146, episilon: 7.567398876139021\n","Client: 39 ACC: 0.7765869498252869, episilon: 7.567398876139021\n","Client: 41 ACC: 0.7534013390541077, episilon: 7.567398876139021\n","Client: 14 ACC: 0.7867711186408997, episilon: 7.567398876139021\n","Client: 36 ACC: 0.7957860827445984, episilon: 7.567398876139021\n","Client: 7 ACC: 0.7966251969337463, episilon: 7.567398876139021\n","Client: 13 ACC: 0.7796609997749329, episilon: 7.567398876139021\n","Client: 6 ACC: 0.7911073565483093, episilon: 7.567398876139021\n","Round: 9\n","Acc: 0.8007216494845361\n","Epsilon: 7.567398876139021\n","Client: 12 ACC: 0.7889610528945923, episilon: 7.998531280611128\n","Client: 34 ACC: 0.8133803009986877, episilon: 7.998531280611128\n","Client: 43 ACC: 0.7990033030509949, episilon: 7.998531280611128\n","Client: 10 ACC: 0.7794238924980164, episilon: 7.998531280611128\n","Client: 33 ACC: 0.7797173857688904, episilon: 7.998531280611128\n","Client: 2 ACC: 0.7725040912628174, episilon: 7.998531280611128\n","Client: 31 ACC: 0.7973199486732483, episilon: 7.998531280611128\n","Client: 17 ACC: 0.7838948369026184, episilon: 7.998531280611128\n","Client: 47 ACC: 0.8009827733039856, episilon: 7.998531280611128\n","Client: 15 ACC: 0.7902097702026367, episilon: 7.998531280611128\n","Client: 8 ACC: 0.7952302694320679, episilon: 7.998531280611128\n","Client: 27 ACC: 0.776157796382904, episilon: 7.998531280611128\n","Client: 6 ACC: 0.7759170532226562, episilon: 7.998531280611128\n","Client: 38 ACC: 0.7762596011161804, episilon: 7.998531280611128\n","Client: 21 ACC: 0.7906588912010193, episilon: 7.998531280611128\n","Client: 13 ACC: 0.8209825158119202, episilon: 7.998531280611128\n","Client: 35 ACC: 0.808474600315094, episilon: 7.998531280611128\n","Client: 26 ACC: 0.8034970760345459, episilon: 7.998531280611128\n","Client: 7 ACC: 0.8021201491355896, episilon: 7.998531280611128\n","Client: 23 ACC: 0.8098106980323792, episilon: 7.998531280611128\n","Client: 16 ACC: 0.7785947918891907, episilon: 7.998531280611128\n","Client: 36 ACC: 0.78407222032547, episilon: 7.998531280611128\n","Client: 40 ACC: 0.7833189964294434, episilon: 7.998531280611128\n","Client: 41 ACC: 0.7939493060112, episilon: 7.998531280611128\n","Client: 48 ACC: 0.8093289732933044, episilon: 7.998531280611128\n","Client: 14 ACC: 0.8181056380271912, episilon: 7.998531280611128\n","Client: 5 ACC: 0.7938408851623535, episilon: 7.998531280611128\n","Client: 11 ACC: 0.7928994297981262, episilon: 7.998531280611128\n","Client: 0 ACC: 0.7935702204704285, episilon: 7.998531280611128\n","Client: 42 ACC: 0.795121967792511, episilon: 7.998531280611128\n","Client: 25 ACC: 0.8104149699211121, episilon: 7.998531280611128\n","Client: 46 ACC: 0.8021885752677917, episilon: 7.998531280611128\n","Client: 20 ACC: 0.7901444435119629, episilon: 7.998531280611128\n","Client: 29 ACC: 0.7677841186523438, episilon: 7.998531280611128\n","Client: 45 ACC: 0.780889630317688, episilon: 7.998531280611128\n","Client: 3 ACC: 0.8204924464225769, episilon: 7.998531280611128\n","Client: 9 ACC: 0.7977617979049683, episilon: 7.998531280611128\n","Client: 37 ACC: 0.798353910446167, episilon: 7.998531280611128\n","Client: 39 ACC: 0.8155422806739807, episilon: 7.998531280611128\n","Client: 28 ACC: 0.7883149981498718, episilon: 7.998531280611128\n","Client: 19 ACC: 0.7909162044525146, episilon: 7.998531280611128\n","Client: 44 ACC: 0.8033755421638489, episilon: 7.998531280611128\n","Client: 32 ACC: 0.8131600618362427, episilon: 7.998531280611128\n","Client: 30 ACC: 0.7948303818702698, episilon: 7.998531280611128\n","Client: 22 ACC: 0.7967959642410278, episilon: 7.998531280611128\n","Client: 24 ACC: 0.8006756901741028, episilon: 7.998531280611128\n","Client: 1 ACC: 0.7963761687278748, episilon: 7.998531280611128\n","Client: 18 ACC: 0.7992926836013794, episilon: 7.998531280611128\n","Client: 49 ACC: 0.8027210831642151, episilon: 7.998531280611128\n","Client: 4 ACC: 0.7844756245613098, episilon: 7.998531280611128\n","Round: 10\n","Acc: 0.8150515463917526\n","Epsilon: 7.998531280611128\n","Federated Learning Client Training Finished\n"]}],"source":["best_acc = 0\n","for round in range(ROUNDS): # Changed to one for practice. ROUND\n","\n","    random_index = np.random.choice(NUM_CLIENTS, int(sample_rate*NUM_CLIENTS), replace=False)\n","    for index in random_index:\n","        users[index].train() # training the user for each round.\n","    # for index in random_index:users[index].set_model_state_dict2(torch.load(client_weights[index]))\n","\n","    # Saving the models and the weight in the last round\n","    if round == ROUNDS - 1:\n","        saveWeights(users, folder_name)\n","\n","    if round == ROUNDS - 2:\n","        saveServerWeights(server, folder_name)\n","\n","    if MODE == \"LDP\":\n","        weights_agg = agg_weights([users[index].get_model_state_dict() for index in random_index])\n","        for i in range(NUM_CLIENTS):\n","            users[i].set_model_state_dict(weights_agg)\n","    else:\n","        server.agg_updates([users[index].get_model_state_dict() for index in random_index])\n","        for i in range(NUM_CLIENTS):\n","            users[i].set_model_state_dict(server.get_model_state_dict())\n","\n","    print(f\"Round: {round+1}\")\n","    acc = evaluate_global(users, test_dataloaders, range(NUM_CLIENTS))\n","    if acc > best_acc:\n","        best_acc = acc\n","    if MODE == \"LDP\":\n","        eps = max([user.epsilon for user in users])\n","        print(f\"Epsilon: {eps}\")\n","        if eps > target_epsilon:\n","            break\n","\n","print('Federated Learning Client Training Finished')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1757610417713,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"EKgcaCqQsu7Y","outputId":"f1d51c7e-6cb5-4b3a-cd15-3f83c0e6baaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train data shape: torch.Size([1194, 1, 28, 28]), training labels shape: torch.Size([1194])\n","Test data shape: torch.Size([194, 1, 28, 28]), test labels shape: torch.Size([194])\n"]}],"source":["training_data = torch.load('./FL_LDP_data/client_train_data/client_train_00.pt')\n","testing_data = torch.load('./FL_LDP_data/client_test_data/client_test_00.pt')\n","\n","x_train = training_data['images']\n","y_train = training_data['labels']\n","x_test = testing_data['images']\n","y_test = testing_data['labels']\n","# convert the labels to one_hot_encoding\n","num_classes = len(torch.unique(y_train))\n","\n","print(f\"Train data shape: {x_train.shape}, training labels shape: {y_train.shape}\")\n","print(f\"Test data shape: {x_test.shape}, test labels shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1757610451105,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"b3dh1P-Bsu7Y"},"outputs":[],"source":["def strip_prefix(state_dict, prefix=\"_module.\"):\n","    \"\"\"\n","    Strip a prefix from the state_dict keys.\n","    Args:\n","        state_dict (dict): The state_dict with the potentially prefixed keys.\n","        prefix (str): The prefix to remove.\n","    Returns:\n","        dict: The state_dict with the prefix removed from the keys.\n","    \"\"\"\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        if k.startswith(prefix):\n","            new_state_dict[k[len(prefix):]] = v\n","        else:\n","            new_state_dict[k] = v\n","    return new_state_dict"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1757610463767,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"X1mdOaYwsu7Z","outputId":"dc2927f9-dab5-475e-c935-9de34902904d"},"outputs":[{"output_type":"stream","name":"stdout","text":["The accuray on the test data is :  80.92783\n"]}],"source":["model_path = './FL_LDP_data/client_model_weights/weight_user00.pth'  # Path to your saved model weights\n","model = mnist_fully_connected(num_classes)\n","\n","# Load the state_dict\n","state_dict = torch.load(model_path)\n","# Strip the \"_module.\" prefix if it exists\n","state_dict = strip_prefix(state_dict, prefix=\"_module.\")\n","# Load the modified state_dict into the model\n","model.load_state_dict(state_dict)\n","# Set the model to evaluation mode\n","\n","# Check the models accuracy on the test data\n","with torch.no_grad():\n","    test_logits, _ = model(x_test)\n","\n","prediction = torch.sum(torch.argmax(test_logits, axis = 1) == y_test) / len(y_test)\n","print('The accuray on the test data is : ', prediction.numpy() * 100)"]},{"cell_type":"markdown","metadata":{"id":"zO56O_Hgsu7Z"},"source":["#### Visualize the train data and labels"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1757610473019,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"PlwZHCcRsu7a","outputId":"023a75f3-516a-485a-806e-93cc98ee6955"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x700 with 10 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABJ4AAAIYCAYAAAAsKiYVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARxpJREFUeJzt/XuYV3W5P/7fA4OAnFFIUTwQnrjEs+CJJNFwm3VhEpiWuBXt42kjmZal4jY020qZmaARaoaJurU8V55IS5HyiOlGSRRUEDkniBzW74++8tPktWZ8My/mwONxXV7X7v2ctdbtbO95zzxZzKoqiqIIAAAAAKhjzep7AAAAAACaJsUTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACALxVMDMHPmzKiqqoorrriizs756KOPRlVVVTz66KN1dk5g3ewwNF72Fxo3OwyNl/3deCieKnTDDTdEVVVV/PWvf63vUbKaNGlS7L///tGmTZvo2LFjHHDAAfHwww/X91iw3uwwNF4bw/7ecsstsddee0WrVq2iS5cucdJJJ8W7775b32NBnWjqO3zRRRdFVVXVJ/5p1apVfY8G662p7++dd94ZAwcOjG7dukXLli1j6623jsGDB8e0adPqe7RGrbq+B6Dhuuiii+Liiy+OwYMHxwknnBArV66MadOmxZtvvlnfowG1YIehcRo7dmycdtppMWDAgPjxj38cs2fPjp/+9Kfx17/+NaZMmeKHV2gkxo4dG23btl37v5s3b16P0wC18cILL0SnTp1ixIgRsfnmm8ecOXNiwoQJ0adPn3jiiSdi9913r+8RGyXFE+v05JNPxsUXXxxjxoyJkSNH1vc4wKdkh6Fx+uCDD+J73/tefO5zn4s//vGPUVVVFRERBxxwQHzpS1+KX/ziF3HmmWfW85RAbQwePDg233zz+h4D+BQuvPDCT7w2fPjw2HrrrWPs2LExbty4epiq8fNX7TL64IMP4sILL4y99947OnToEG3atIl+/frFI488kjzmJz/5SWy77bbRunXrOPjgg9d5S9/LL78cgwcPjs6dO0erVq1in332ibvuuqvGeZYtWxYvv/xyrW7Vv/LKK2OLLbaIESNGRFEU8c9//rPGY6CpscPQeDXW/Z02bVosWrQohg4durZ0iog48sgjo23btnHLLbfUeC1oChrrDn9UURSxZMmSKIqi1sdAU9AU9vejunbtGptuumksWrSoouNRPGW1ZMmSGD9+fPTv3z9+9KMfxUUXXRTz5s2LgQMHxrPPPvuJj//Vr34VV111VZx++ulx3nnnxbRp0+KQQw6JuXPnrv2YF198Mfbbb7946aWX4rvf/W6MGTMm2rRpE4MGDYo777yzdJ6nnnoqdtlll7j66qtrnP2hhx6KfffdN6666qro0qVLtGvXLrbccstaHQtNhR2Gxqux7u+KFSsiIqJ169afyFq3bh3PPPNMrFmzphafAWjcGusOf1SPHj2iQ4cO0a5du/j617/+sVmgKWsK+7to0aKYN29evPDCCzF8+PBYsmRJDBgwoNbH828KKnL99dcXEVFMnTo1+TGrVq0qVqxY8bHXFi5cWHzmM58pTjzxxLWvvfbaa0VEFK1bty5mz5699vUpU6YUEVGMHDly7WsDBgwoevfuXbz//vtrX1uzZk1xwAEHFDvssMPa1x555JEiIopHHnnkE6+NGjWq9N9twYIFRUQUm222WdG2bdvi8ssvLyZNmlQcfvjhRUQU48aNKz0eGgM7DI1XU97fefPmFVVVVcVJJ530sddffvnlIiKKiCjefffd0nNAQ9eUd7goiuLKK68szjjjjGLixInF7bffXowYMaKorq4udthhh2Lx4sU1Hg8NWVPf3w/ttNNOa99327ZtW5x//vnF6tWra308H+eOp4yaN28em2yySURErFmzJhYsWBCrVq2KffbZJ55++ulPfPygQYNiq622Wvu/+/TpE3379o377rsvIiIWLFgQDz/8cAwZMiSWLl0a7777brz77rsxf/78GDhwYLzyyiulvzS4f//+URRFXHTRRaVzf/hXcubPnx/jx4+Pb3/72zFkyJC49957o1evXjF69OhP+6mARskOQ+PVWPd38803jyFDhsSNN94YY8aMiX/84x/x2GOPxdChQ6NFixYREbF8+fJP++mARqex7nBExIgRI+JnP/tZHHvssXH00UfHlVdeGTfeeGO88sorcc0113zKzwQ0Po15fz90/fXXxwMPPBDXXHNN7LLLLrF8+fJYvXp1rY/n4xRPmd14442x2267RatWrWKzzTaLLl26xL333huLFy/+xMfusMMOn3htxx13jJkzZ0ZExKuvvhpFUcQFF1wQXbp0+dg/o0aNioiId955Z71n/vD2/hYtWsTgwYPXvt6sWbMYOnRozJ49O9544431vg40BnYYGq/GuL8REddee20cccQR8e1vfzs++9nPxuc+97no3bt3fOlLX4qI+NhTsqApa6w7vC7HHntsbLHFFvHggw9muwY0JI19f/fff/8YOHBgnHrqqfH73/8+fv3rX8d5551Xp9fYmHiqXUa//vWv44QTTohBgwbFOeecE127do3mzZvHD3/4w5gxY8anPt+Hv9Ph29/+dgwcOHCdH9OzZ8/1mjki1v6yto4dO37isa9du3aNiIiFCxfGNttss97XgobMDkPj1Vj3NyKiQ4cO8bvf/S7eeOONmDlzZmy77bax7bbbxgEHHBBdunSJjh071sl1oCFrzDuc0r1791iwYEHWa0BD0NT2t1OnTnHIIYfExIkT44orrsh2naZM8ZTR7bffHj169Ig77rjjY0+m+bCV/XevvPLKJ16bPn16bLfddhHxr19QGPGvuxgOPfTQuh/4/9OsWbPYY489YurUqfHBBx+svU0yIuKtt96KiIguXbpkuz40FHYYGq/Gur8ftc0226wtiBctWhR/+9vf4uijj94g14b61hR2+KOKooiZM2fGnnvuucGvDRtaU9vfiH/9Nfd13a1F7firdhl9eKdB8ZFHqE6ZMiWeeOKJdX78b3/724/93dSnnnoqpkyZEv/xH/8REf+6U6F///5x7bXXxttvv/2J4+fNm1c6z6d5jOTQoUNj9erVceONN6597f3334+JEydGr169olu3bjWeAxo7OwyNV2Pe33U577zzYtWqVTFy5MiKjofGpjHv8LrONXbs2Jg3b14cfvjhNR4PjV1j3t91/ZW9mTNnxkMPPRT77LNPjcezbu54Wk8TJkyIBx544BOvjxgxIo488si444474qijjoovfvGL8dprr8W4ceOiV69ea3/570f17NkzDjrooDj11FNjxYoVceWVV8Zmm20W55577tqP+fnPfx4HHXRQ9O7dO04++eTo0aNHzJ07N5544omYPXt2PPfcc8lZn3rqqfj85z8fo0aNqvEXq33zm9+M8ePHx+mnnx7Tp0+PbbbZJm666aZ4/fXX4+677679JwgaODsMjVdT3d/LLrsspk2bFn379o3q6ur47W9/G3/4wx9i9OjRse+++9b+EwQNXFPd4W233TaGDh0avXv3jlatWsXjjz8et9xyS+yxxx7xzW9+s/afIGjAmur+9u7dOwYMGBB77LFHdOrUKV555ZX45S9/GStXrozLLrus9p8gPm7DP0ivafjwMZKpf2bNmlWsWbOmuPTSS4ttt922aNmyZbHnnnsW99xzTzFs2LBi2223XXuuDx8jefnllxdjxowpunfvXrRs2bLo169f8dxzz33i2jNmzCiOP/74YosttihatGhRbLXVVsWRRx5Z3H777Ws/pi4eIzl37txi2LBhRefOnYuWLVsWffv2LR544IFKP2XQoNhhaLya+v7ec889RZ8+fYp27doVm266abHffvsVt9566/p8yqBBaeo7PHz48KJXr15Fu3btihYtWhQ9e/YsvvOd7xRLlixZn08bNAhNfX9HjRpV7LPPPkWnTp2K6urqolu3bsUxxxxTPP/88+vzadvoVRXFR+5/AwAAAIA64nc8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIoro2H7RmzZp46623ol27dlFVVZV7JmhUiqKIpUuXRrdu3aJZs4bZ5dphSGvoO2x/Ia2h72+EHYYyDX2H7S+Uq+0O16p4euutt6J79+51Nhw0RbNmzYqtt966vsdYJzsMNWuoO2x/oWYNdX8j7DDURkPdYfsLtVPTDteqeGrXrt3ak7Vv375uJoMmYsmSJdG9e/e1e9IQ2WFIa+g7bH8hraHvb4QdhjINfYftL5Sr7Q7Xqnj68LbC9u3bWzhIaMi339phqFlD3WH7CzVrqPsbYYehNhrqDttfqJ2adrjh/UVaAAAAAJoExRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFlU1/cAbHiTJ09OZjfffHMyu+6665LZn/70p9Jr9uvXr+bBYCOyYMGCio8dO3ZsMttll10qynbcccfSazZv3rzmwQAAAP6NO54AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGRRXd8DUJnZs2eX5pMnT05mJ554YjJbtWpVMmvWLN1TXnHFFaXz9OvXrzSHjU3nzp1L85UrVyazXXfdNZkdddRRFc1z9tlnl+Y//OEPk1l1tbcSAABg3dzxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8/AbsDKHqd+/PHHlx47efLkiq5ZVVWVzFq0aJHMJk6cWNH1YGP1t7/9rTT/5je/mcyefvrpuh4nxowZU5qPHDkymXXr1q2uxwFgI7J48eJk9otf/CKZvfHGGznGKbXJJpsks2OPPTbLNbfffvtk1qlTpyzXZOPywAMPlOZHHHFEMiuKIpmV/WxZ5qmnnkpm++yzT0XnpH654wkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBbV9T3Axu7dd99NZt/4xjeS2eTJkyu+ZvPmzZPZDTfckMxyPSIWmqrbbrstmZ111lmlx7799tsVXbNnz57JbMWKFcls1qxZFV0PGrMPPvggmc2dOzeZ/fnPfy4977Rp05LZpZdemszKHjvdtWvXZFb22OmIiO7du5fmsCGUvQftu+++yezVV1/NMU4WP/7xj7Oct1WrVsmsZcuWFZ1zt912S2bDhg1LZieeeGJF16Nhu+CCC0rzsvenHMc9+OCDyaym97TNNtssmVVXqz/qizueAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABk4XmCG8D777+fzO69995k9uijj1Z8ze233z6ZXXLJJcls6NChFV8TNkZPPPFEMjvttNOS2fz58yu+5u67757Mbr755mQ2derUZFY2a0TEJptsUvNg0ACNHz8+mY0bNy6ZPfvss8msKIrSa5Y9PrrS7J133klm++23X+k8b775ZmkOG8Lo0aOT2auvvprMdt5552Q2ZMiQZNa+fftkdvfddyeziPL3y2XLlpUem0PZzxJlWZnHHnssmb388svJ7MQTT6zoejRs99xzT2n+0EMPVZRNmzYtmf31r39NZt///vcryiIiDjzwwGRW9jXjhBNOSGZt27YtvSY1c8cTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsqoqangkcEUuWLIkOHTrE4sWLSx9NujFbvXp1MrvvvvuS2aBBgyq6Xps2bUrz66+/PpkdffTRFV2TdWsM+9EYZmzIVqxYkcyGDh2azO66666Kr/nlL385mU2cODGZtWrVKpmVzbrVVluVzvPTn/60NG/MGvp+NPT5NpSyR5iPGDEimU2YMCGZlX0LVFVVlcwOPvjgZBYRsfvuuyezww47LJk999xzyazs8dFls0aUPzr+iCOOKD22oWsM+9EYZqwLf/7zn0vzgQMHJrOyXVywYEEya9myZc2DVWDRokXJbMaMGclsypQpGaapXNlj7sv+//G1r30tmbVr1269Zvp3DX0/Gvp8Dd3KlSuT2dy5c5PZnXfemcxuvPHG0ms+/fTTyazs/bJDhw7J7Itf/GIyu/DCC0vn6d69ezIr+769sajtjrjjCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALKoru8BmoqbbropmZ100kkVnXPTTTdNZjNmzCg9tkuXLhVdE/ikU045JZndddddFZ1zhx12KM1/9atfJbM2bdoks5UrVyazZcuWJbPzzz+/dB6obyeffHIyu+WWW5JZVVVVMvvMZz6TzH76058ms69+9avJbH0cccQRyey1115LZhMmTCg978SJEyu6Jvy7xYsXJ7MhQ4aUHlv2HnT66acns5YtW9Y8WB3r2LFjMtt7770ryurDaaedVt8jsJFr0aJFMtt6662T2ZlnnllRFhFx4403JrOy98OHHnoomd18880VZRERvXr1SmaTJk2q6LjGyB1PAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyqK7vARqT6dOnJ7Mf/vCHdX69v/zlL8msS5cudX492JjNmzcvmdX0mNSUVq1aJbPx48eXHtu+ffuKrln2deOee+5JZs2a+XMI6tfJJ59cmt9yyy3JrCiKZPblL385mV177bXJrGvXrqXzbGhl85T9+0dEvP3223U9DhupQYMGJbOa/jurqqpKZmeccUalIwF8zLBhwyrKli9fnszKvpd46KGHSueZNm1aMjvwwAOT2cyZM5NZhw4dSq/ZEPlJAwAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFtX1PUBDsmTJktL8uOOOS2avvvpqMmvevHkyK3uk+q677lo6D1B3hg8fnsxWr15d0TkvueSSZNavX7+KzlmT/fbbL5k1a+bPGqhf77zzTjKbMGFC6bFlj2I/6aSTktnll1+ezBra44gr/fyUfW4iInbfffeKZ2LjM2fOnGQ2derUis976aWXJrOddtqp4vMC9avs++QVK1bU+fXKvkZFRNx2223JbNKkScls0aJFyez1119PZjW9B5d9rzFo0KCKjmuM/BQCAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACCL6voeYEMriiKZ/frXvy499umnn67omkOHDk1mxx9/fEXnBD695cuXJ7MXX3yxonNuueWWyezkk0+u6Jzro2XLlhv8mlBbZY9TL3t/rslJJ52UzBrT44jvuuuuZFb2+OiaHuV8zDHHVDwTG5/Bgwcns2XLliWzNm3alJ63bE/L/POf/0xm//jHP5LZggULklnZrkVEvPbaa8ls++23Lz02ZbvttktmZ5xxRumxzZq5V4D69fe//z2ZnXfeecnsnnvuyTFOqbLvJ2p6v0w57rjjktmxxx5beuz++++fzBrT9yjry1cxAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZVNf3ABvarFmzktmZZ55Z8Xlbt26dzK699tqKz9tYPPbYY6X56tWrk9l+++2XzFq1alXxTPDv7r///mRW9kjmMmeddVZFx5V9LYoof/zs3/72t2S2YsWKZNa1a9dkdsQRR5TOM2DAgNIcauP5559PZjU94rgs79u3b8UzbWjjx49PZt/61reSWdm//1577VV6zcb0+aH+vfjiixUd9/7775fmu+yyS0XnXblyZTJbsmRJRedsaG644YbS/OGHH05mHTt2rNthYB2WLl2azO6+++5kVtN7e8qWW26ZzH74wx9WdM6IiD322COZ9ezZM5mV/Uxa6b/jxsYdTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAsqiu7wE2tGuvvTbLec8///xktummm2a5ZplVq1Yls+uvvz6ZzZgxI5mVPQJ64cKFtRtsHb773e8ms9GjRyczj67k0zrnnHPq/Jxlj4cve8T57NmzS8+7fPnyZJbjv/1rrrmmNJ80aVIy+/KXv1zX49BElT0Cef/996/4vFOmTElmffv2rfi8KbNmzSrN77zzzmR21llnJbOy3S6KIpmNGTOmdB74NDp37pzMFi9enMxWr15det758+dXPFPK9ttvn8y6du2azPbbb7/S8+6+++4VzfPKK68ks7Kvf88++2zpeX/zm98ks1NPPbXGuWB9lb2XPvnkk8ms7Gfkhx56KJmVfa059NBDk1lExJZbblmaUz/c8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZVNf3ADksX748mb344osVn7dr167JbMiQIRWfN2XNmjXJbOrUqaXHjho1Kpn98Y9/rHimHC677LJkdvHFFyez5s2b5xiHJuyf//xnnZ9z4sSJdX7OiPL/vlu3bp3Mdt1112Q2ZcqUZLZixYrSeY4//vhk9vrrryezDh06lJ6XjUvfvn2TWVVVVemxZflhhx2WzPbZZ5+aB/uUJk+eXJqXzVpptueeeyaz/fffv3Qe+DSeffbZZPab3/wmmS1btqzia1ZXp38kGTx4cDLr2LFjMmvVqlXF81SqKIpk9tprryWzW265pfS8d955ZzI79dRTax4MMurTp08yu++++5LZddddl8xGjhyZzLbaaqvSef7whz8ks4MPPjiZtWjRovS8rB93PAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyCL97NJGrOxxxOvzaNUvfelLyaxHjx4Vnzel7LGrBxxwQJ1fL6L88ZRf+9rXktm+++5bet7vfe97yWzGjBnJ7LHHHktm/fv3L70m1LdNN900mZ133nmlx371q19NZjvuuGMyW7NmTTI744wzktm4ceNK51myZEkyK/tatccee5SeFz70l7/8pTQ/7LDDktk///nPZDZ58uRkVvbo87LvJcqOq0mlx/785z9PZh4BTV1q165dMjvllFM24CSNT9nXjY4dO264QaCBqK5O1w2nnXZaMuvdu3dFx0VEfOELX0hm/fr1S2YPP/xwMmvevHnpNamZO54AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSRfr5hI9aqVatk1qFDh2TWpUuX0vOOHj264plSnnzyyWT2+c9/vs6vFxFx/fXXJ7Njjz02mZU9DrMmK1asSGbHH398Mps0aVIy69+/f8Xz0DTNmTOnNC975Hqlvve97yWzr3/968ls5513rvNZIiKaNUv/ecJXv/rVZDZu3Lgc40Ct9e3btzSfMWNGMrvqqqsquua0adOS2a677prMhgwZUnreww8/PJmVfZ0aPnx4Mqvp8wMATUW/fv2SWdnPhxHl79+PP/54Mrv00kuT2QUXXFB6TWrmjicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFlU1/cAObzxxhvJ7De/+U0y69q1a+l527ZtW9E8d9xxRzIbO3ZsMvvggw+S2V577VV6zQsvvDCZHXHEEcmsefPmpedNWbVqVWn+zDPPVHTeLbbYoqLj2Di9/fbbpfny5cvr/JqjRo1KZi1atKjz69XkvffeS2Zf/epXKz7vpptumsy23HLLis8LtdWlS5dk9oMf/GADThJx1VVXleZz5sxJZkVRJLOyR0ADDV/Zfpf9fALUXq9evUrz3XbbLZm98MILycz3s3m54wkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBbV9T1ADp/5zGeS2WabbZbManoU+7x585LZtttum8xWr16dzB5++OFkdvDBByezCRMmJLOIiO222640r2urVq0qze+///6Kzjt48OCKjmPjtOOOO5bmHTp0SGaLFy+u6JrTpk1LZnvuuWdF54yIeO+995LZddddl8wuvfTSZLZgwYKK57n11luTWdnXXGiKRo4cWZpXVVUls7J9Of744yueCah/M2bMSGb33XffBpwENl7PP/98Mit7f16f79upmTueAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIIvq+h4gh5YtWyazYcOGJbMf/OAHpecdNGhQMrv++uuTWceOHUvPm/Kzn/0smW233XYVnTOXH/3oR6X5yy+/XNF5d95554qOY+PUpk2b0rxsb5577rmKrnnAAQcks+bNm1d0zoiI1atXJ7MVK1ZUfN6Ur33ta6X55z//+Tq/JjRkZ511VjIriqLi8955553JrEOHDhWfFz6N999/P5nddtttyezYY49NZuvznteYTJ06NZmdcsopWa553HHHZTkvG5fly5cns8suu6z02BEjRiSzzp07VzxTJc4555zSvOw9ukWLFsnMe3Be7ngCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJBFdX0PsKGddNJJyeymm24qPfb5559PZt/4xjeS2Wc/+9lk1rt372S2+eabl86TQ9kj5X/84x8ns5tvvrnia/bp0yeZVVVVVXxe+Hd/+MMfktnnPve5ZPZ///d/yWzFihXrNVNK2aNgy/Zim222SWY/+9nPktkXv/jF0nmaNfPnFDQ977zzTjKbMGFCMqvpvaks79u3b82DQWZHHXVUMvv973+fzGbPnp3M2rdvv14z1bUZM2Yks06dOpUee8sttySzmTNnJrOyx9WX6devX2k+ePDgis4LH/XMM88ks9GjR5ceO2zYsGTWuXPniuZZtWpVMjvnnHOS2fjx40vPW/YefNFFFyWznj17lp6X9eMnCQAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWVTX9wAbWvfu3ZNZ2eNjIyJ22mmnZPb3v/+9oqxM2SOXx4wZU9E5IyL+9Kc/JbNf/epXyWzJkiXJrF27dqXXPPvss5PZN77xjWRW0yOr4dPo0qVLMnvyySeTWdlelP23XfaY2JqUfa06+eSTk1nZ42dbtWpV8TzQFD388MPJ7L333ktma9asKT3v5MmTK54JNoQHHnggmZV97/X9738/xzhNRtnn7pRTTklmP/7xj0vP27p164pngg81a5a+56Rly5alx1533XXJ7LLLLktm8+fPT2YXXHBBMrv22mtL5ynTtWvXZHbGGWdUfF7WjzueAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkUV3fAzQkPXv2LM1Xr169gSbJ6+ijj05mP/3pTzfgJNBwdOjQIZmdeeaZFWVAwzZt2rRkVvZY9LJHUkdEbL/99hXPBBvCRRddlMxyfS+4YsWKZLZq1apktskmmySzoigqOm597LnnnsnsBz/4QTI74IADcowDtbbffvsls5rety6//PJkdsMNNySzZcuWJbP33nuv9JopQ4YMKc0vu+yyZNauXbuKrsn6c8cTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsqut7AACA+nDJJZcks2bN0n82t2bNmhzjwAYzatSoirL1sXDhwmRW9lj1jh07JrOiKJKZx6ZD7f3xj38szffbb79kNnv27GS26aabJrNzzjknmR100EHJ7LDDDktmEREtW7Yszakf7ngCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJBFdX0PAABQH6666qpkNnLkyGQ2efLk0vNuscUWFc8ETVWnTp0qyoD8unXrVpq/8cYbG2gSmip3PAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAW1fU9AABAfTjzzDMrygAAqD13PAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgi+rafFBRFBERsWTJkqzDQGP04V58uCcNkR2GtIa+w/YX0hr6/kbYYSjT0HfY/kK52u5wrYqnpUuXRkRE9+7d13MsaLqWLl0aHTp0qO8x1skOQ80a6g7bX6hZQ93fCDsMtdFQd9j+Qu3UtMNVRS3q5TVr1sRbb70V7dq1i6qqqjodEBq7oihi6dKl0a1bt2jWrGH+7VU7DGkNfYftL6Q19P2NsMNQpqHvsP2FcrXd4VoVTwAAAADwaTW8WhkAAACAJkHxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTw3AzJkzo6qqKq644oo6O+ejjz4aVVVV8eijj9bZOYF1s8PQeNlfaNzsMDRe9nfjoXiq0A033BBVVVXx17/+tb5HyWrSpEmx//77R5s2baJjx45xwAEHxMMPP1zfY8F6a+o7fOedd8bAgQOjW7du0bJly9h6661j8ODBMW3atPoeDdZbU9/f7bbbLqqqqtb5zw477FDf48F6a+o7fMcdd8TQoUOjR48esemmm8ZOO+0UZ599dixatKi+R4P1Zn+pRHV9D0DDddFFF8XFF18cgwcPjhNOOCFWrlwZ06ZNizfffLO+RwNq8MILL0SnTp1ixIgRsfnmm8ecOXNiwoQJ0adPn3jiiSdi9913r+8RgYQrr7wy/vnPf37stddffz3OP//8+MIXvlBPUwG1dcopp0S3bt3i61//emyzzTbxwgsvxNVXXx333XdfPP3009G6dev6HhFIsL95KJ5YpyeffDIuvvjiGDNmTIwcObK+xwE+pQsvvPATrw0fPjy23nrrGDt2bIwbN64epgJqY9CgQZ94bfTo0RERcdxxx23gaYBP6/bbb4/+/ft/7LW99947hg0bFhMnTozhw4fXz2BAjexvHv6qXUYffPBBXHjhhbH33ntHhw4dok2bNtGvX7945JFHksf85Cc/iW233TZat24dBx988Dr/WszLL78cgwcPjs6dO0erVq1in332ibvuuqvGeZYtWxYvv/xyvPvuuzV+7JVXXhlbbLFFjBgxIoqi+MSfvMLGoDHv8Lp07do1Nt10U7cKs1Foavt78803x/bbbx8HHHBARcdDY9OYd/jff2iNiDjqqKMiIuKll16q8Xho7Owv/07xlNGSJUti/Pjx0b9///jRj34UF110UcybNy8GDhwYzz777Cc+/le/+lVcddVVcfrpp8d5550X06ZNi0MOOSTmzp279mNefPHF2G+//eKll16K7373uzFmzJho06ZNDBo0KO68887SeZ566qnYZZdd4uqrr65x9oceeij23XffuOqqq6JLly7Rrl272HLLLWt1LDQVjXmHP7Ro0aKYN29evPDCCzF8+PBYsmRJDBgwoNbHQ2PVFPb3Q88880y89NJLceyxx37qY6Gxako7HBExZ86ciIjYfPPNKzoeGhP7yycUVOT6668vIqKYOnVq8mNWrVpVrFix4mOvLVy4sPjMZz5TnHjiiWtfe+2114qIKFq3bl3Mnj177etTpkwpIqIYOXLk2tcGDBhQ9O7du3j//ffXvrZmzZrigAMOKHbYYYe1rz3yyCNFRBSPPPLIJ14bNWpU6b/bggULiogoNttss6Jt27bF5ZdfXkyaNKk4/PDDi4goxo0bV3o8NAZNeYc/aqeddioiooiIom3btsX5559frF69utbHQ0O0sezvh84+++wiIoq///3vn/pYaIg2th0uiqI46aSTiubNmxfTp0+v6HhoKOwvlXDHU0bNmzePTTbZJCIi1qxZEwsWLIhVq1bFPvvsE08//fQnPn7QoEGx1VZbrf3fffr0ib59+8Z9990XERELFiyIhx9+OIYMGRJLly6Nd999N959992YP39+DBw4MF555ZXSX/zdv3//KIoiLrrootK5P/xrdfPnz4/x48fHt7/97RgyZEjce++90atXr7W/ZwKausa6wx91/fXXxwMPPBDXXHNN7LLLLrF8+fJYvXp1rY+Hxqop7O+Hs99yyy2x5557xi677PKpjoXGrKnscMS//qrsL3/5yzj77LM9mZKNgv3l3/nl4pndeOONMWbMmHj55Zdj5cqVa1/ffvvtP/Gx6/oPeccdd4xbb701IiJeffXVKIoiLrjggrjgggvWeb133nnnY0tbiQ9/U3+LFi1i8ODBa19v1qxZDB06NEaNGhVvvPFGbLPNNut1HWgMGuMOf9T++++/9v8+5phj1v7gesUVV9TZNaChauz7GxExefLkePPNNz3og41SU9jhxx57LE466aQYOHBgXHLJJXV6bmjI7C8fpXjK6Ne//nWccMIJMWjQoDjnnHOia9eu0bx58/jhD38YM2bM+NTnW7NmTUREfPvb346BAweu82N69uy5XjNHxNpf1taxY8do3rz5x7KuXbtGRMTChQsVTzR5jXWHUzp16hSHHHJITJw4UfFEk9dU9nfixInRrFmz+NrXvlbn54aGrCns8HPPPRdf/vKXY9ddd43bb789qqv96MXGwf7y73z2Mrr99tujR48ecccdd0RVVdXa10eNGrXOj3/llVc+8dr06dNju+22i4iIHj16RMS/7kQ69NBD637g/0+zZs1ijz32iKlTp8YHH3yw9jbJiIi33norIiK6dOmS7frQUDTWHS6zfPnyWLx4cb1cGzakprC/K1asiP/93/+N/v37R7du3TbINaGhaOw7PGPGjDj88MOja9eucd9990Xbtm2zXxMaCvvLv/M7njL68G6hoijWvjZlypR44okn1vnxv/3tbz/2d1OfeuqpmDJlSvzHf/xHRPzrbqP+/fvHtddeG2+//fYnjp83b17pPJ/mMZJDhw6N1atXx4033rj2tffffz8mTpwYvXr18g0wG4XGvMPvvPPOJ16bOXNmPPTQQ7HPPvvUeDw0do15fz903333xaJFi+K4446r9THQVDTmHZ4zZ0584QtfiGbNmsXvf/97f2DLRsf+8u/c8bSeJkyYEA888MAnXh8xYkQceeSRcccdd8RRRx0VX/ziF+O1116LcePGRa9evdb+Au+P6tmzZxx00EFx6qmnxooVK+LKK6+MzTbbLM4999y1H/Pzn/88DjrooOjdu3ecfPLJ0aNHj5g7d2488cQTMXv27HjuueeSsz711FPx+c9/PkaNGlXjL1b75je/GePHj4/TTz89pk+fHttss03cdNNN8frrr8fdd99d+08QNHBNdYd79+4dAwYMiD322CM6deoUr7zySvzyl7+MlStXxmWXXVb7TxA0YE11fz80ceLEaNmyZRx99NG1+nhobJrqDh9++OHxj3/8I84999x4/PHH4/HHH1+bfeYzn4nDDjusFp8daNjsL59KPTxJr0n48DGSqX9mzZpVrFmzprj00kuLbbfdtmjZsmWx5557Fvfcc08xbNiwYtttt117rg8fI3n55ZcXY8aMKbp37160bNmy6NevX/Hcc8994tozZswojj/++GKLLbYoWrRoUWy11VbFkUceWdx+++1rP6YuHiM5d+7cYtiwYUXnzp2Lli1bFn379i0eeOCBSj9l0KA09R0eNWpUsc8++xSdOnUqqquri27duhXHHHNM8fzzz6/Ppw0ahKa+v0VRFIsXLy5atWpVfOUrX6n00wQNVlPf4bJ/t4MPPng9PnNQ/+wvlagqio/c/wYAAAAAdcTveAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkEV1bT5ozZo18dZbb0W7du2iqqoq90zQqBRFEUuXLo1u3bpFs2YNs8u1w5DW0HfY/kJaQ9/fCDsMZRr6DttfKFfbHa5V8fTWW29F9+7d62w4aIpmzZoVW2+9dX2PsU52GGrWUHfY/kLNGur+RthhqI2GusP2F2qnph2uVfHUrl27tSdr37593UwGTcSSJUuie/fua/ekIbLDkNbQd9j+QlpD398IOwxlGvoO218oV9sdrlXx9OFthe3bt7dwkNCQb7+1w1CzhrrD9hdq1lD3N8IOQ2001B22v1A7Ne1ww/uLtAAAAAA0CYonAAAAALJQPAEAAACQRa1+xxP5/OlPf0pmp556ajKbMmVK6Xnbtm1b8UwAAAAAdcEdTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAsqiu7wE2drNnz05mL730UkXHRUTsvPPOFc8EAAAAUBfc8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZVNf3ABu78ePHJ7NmzdK9YKtWrXKMAwAAAFBn3PEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACCL6voeYGPwyiuvJLPJkycns4EDByaz7bbbbn1GAgAA1mHp0qXJ7PXXX09mEyZMSGbPPvtsMnv00UdL5+nevXsy+5//+Z9kNmjQoGTWsmXL0mtCQ/Xuu++W5gceeGAye/XVVyu65po1a5JZv379So+97777klnbtm0rmqcxcscTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsqut7gI3BpEmTkllRFMns+9//fo5xgA3kd7/7XTJ7+OGHS4/92c9+lsx22mmnZDZy5MiaB1uHr3zlK6X55ptvXtF5AaA+PProo8nsW9/6Vumxr7/+ejJbsWJFMlu+fHmNc61LVVVVaT5r1qxkduyxxyazP/zhD8lswIABNQ8GDdDo0aNL8xkzZiSzmnYtpVmz9P06f/nLX0qPPe2005LZr371q4rmaYzc8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIIvq+h5gY1D2SMeyRzPuuuuuOcaBjdYtt9ySzB555JFkVumjTleuXJnMiqIoPbbsca/Tp09PZqeeemrNg63DZZddVppfc801yezwww+v6JrwaYwbNy6Zle3vrbfemswqfaxy2ePLIyKGDRuWzNq3b5/Mdtttt2TWunXrmgeDJmjOnDnJ7IYbbkhmo0aNSmarVq2qeJ6WLVsms69//evJrHfv3snslVdeKb3mxIkTk9ny5cuTWdn3LwMGDCi9JjRU/+///b/S/KabbkpmixcvrutxanTvvfcmswcffDCZHXrooTnGqTfueAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkEV1fQ+wMbj//vuTWY8ePZJZhw4dcowDjdqNN96YzM4666zSY5csWVLH0zQdr7/+emk+fPjwZPbMM88ksy5dulQ8E3zUddddl8z22GOPZPaf//mfGaYpd8wxxySzhQsXJrP27dsnsyeffDKZ7bzzzrUbDBqoWbNmJbMhQ4YksylTpiSzqqqqiueZMGFCMjvkkEOSWffu3Su63t///vfS/IEHHkhms2fPTmbz58+vaB5oyGp6z5s0aVIyO/nkk5PZsmXLktnpp5+ezC655JLSeRYvXpzMTjvttGQ2ffr00vM2Nu54AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQRXV9D9BUzJkzJ5mVPTp56NChOcaBJmvFihXJbMmSJRtwkvWz4447luZlj48uO7bsscrf+973ah4s4e23305mRx55ZDIre9Q1fBpTp05NZs2bN9+Ak9Rs1apVyWzu3LnJ7Atf+EIy+6//+q9k9oc//KF2g0FGy5cvL81Hjx6dzK677rpkNn/+/Irm2X777ZPZI488Unps9+7dK7pmpX7zm9+U5m+88UYyq6qqSmannHJKxTNBY3XooYcms5dffjmZvfPOO8ms7GvCjTfeWDrP66+/XppvLNzxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFlU1/cATcW9996bzFauXJnMBg8enGMcoAHo06dPMiv7mhER0blz52R2++23J7Mrr7yyxrnq2tKlSzf4Ndn4NG/evL5HqLXq6vS3V6tWrUpm06dPT2bt27dfr5kgtwcffLA0v+yyyyo6b1VVVTI7++yzk9l///d/J7PWrVtXNMv6+N3vfpfMxowZU3ps2eeg7HuNgQMH1jwYbERatmyZzLp3717ROYuiqDhfvXp1RddsjNzxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgi/TzfvlU3nnnnYqOa9u2bR1PAk3bnnvumcz+67/+awNOUrOZM2cms7333rv02E022SSZzZ49O5m9//77Nc5V1w488MANfk1orE499dRkVvZY5UsuuSTHOFBnWrduXZpvtdVWyaxNmzbJ7NZbb01mvXv3rnmwDajsfX/EiBHJbMWKFaXn7dSpUzIbM2ZMMit7dDxQe/fff38ye/PNN0uPraqqSmbNmzeveKbGxh1PAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyqK7vAZqKF154IZmVPQJ1t912yzFOqSVLliSzhQsXJrPnn38+mdX0OPXOnTvXPBjUwr777ltRVh+eeOKJZHbQQQdtwEnWX4cOHZLZd77znQ04CTR8y5YtS2bPPfdcMmvVqlUy23nnnddrJsjt0EMPLc3feOONDTRJ/bnyyiuT2axZsyo+73/+538ms5q+Bwf+/1atWpXMrrrqqmR27bXXJrPVq1eXXrPse+ixY8eWHtuUuOMJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAW1fU9QGMye/bsZHb//fcnswsuuCCZNW/efL1mSpkzZ04y69u3bzKr9FGv7du3L81/+ctfJrOjjz66omtCQ3fvvffW9wi1dsIJJ5TmP/rRj5LZ5ptvXsfTQON2/vnnJ7O33347md1zzz3JrFu3bus1E1A3ynZ44sSJyawoimT2xS9+sfSaV1xxRc2DARERsWrVqmQ2duzYZHbuuecms7L9raqqKp3npptuSmYDBgwoPbYpcccTAAAAAFkongAAAADIQvEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsqut7gMbkd7/7XTJbvHhxMttll13qfJY5c+aU5n369Elms2fPTmaXXXZZMttrr72S2fDhw0vn+cY3vpHMdtttt2S2ww47lJ4XGrJhw4Ylsz//+c+lx/7pT3+q63HitttuS2ZHHHFE6bGtWrWq63Gg0XrvvfdK80mTJiWzsl3ac889K54JqL3Vq1eX5nPnzk1mO+64YzJbvnx5MjvooIOS2YQJE0rnAWrvqquuSmbnnnvuBpzkX3r16rXBr9kQueMJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAW1fU9wMZg9913r+i4oiiS2emnn1567JtvvpnMpk2blsx22WWXZFZVVZXMnnnmmdJ59tprr2T25S9/OZm99NJLpeeFhmyHHXZIZvfdd1/psd/85jeT2cSJEyua57bbbktmhx9+eEXnhI3R9ddfX5q//fbbyWzEiBHJbMstt6x4JqD2li5dWpp37949mZV9f96yZctkVvaI9y5dupTOAxubWbNmJbM999yz9NiFCxfW9Tjxuc99Lpndf//9pce2atWqrsdplNzxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFlU1/cAG4NVq1ZVdNyKFSuS2Z133ll67LHHHpvMevXqVdE8ZTp16lSa33333clsv/32S2YLFixIZp07d655MGigWrduXZpfe+21yWz69OnJbOrUqcns1ltvTWZf/epXS+f5yle+UppvSKtXry7NH3/88WR28MEH1/U4NFFl791l+1mTb33rWxUfC9TewoULk9khhxyS5ZpPPvlkMtt9992zXJONz/Lly5PZs88+u+EGWU+TJk1KZr/+9a+T2aJFi0rPW1VVVdE8/fr1S2YXXnhhMmvVqlVF19vYuOMJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyELxBAAAAEAW1fU9wMbgtttuS2Znn312lmvusssuWc5bqU033TSZLVu2LJmVPS4UmrLWrVsns80337zOr/fjH/+4NP/KV75S59esVLNm5X9m0rt37w00CU3Zgw8+mMxefPHF0mP33nvvZLbFFltUPBPwcWXfJ+64447JbP78+RVfc9q0acmsV69eFZ8XPurEE09MZi+99FIymzp1akXXK4qiNK+qqqrovJUqm2d9ZjnssMOSWdnP7G3btq34mvyLO54AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGRRXd8DNCaHHnpoRceNHj06mZ111lnJrHnz5smsZ8+epde8+uqrk9lpp52WzNq0aZPMyh49u2bNmtJ5hg8fnsw6d+6czDp06FB6XmiqZs2alcwqfVRuU1HTY3TLvqbAR61atSqZjRw5suLzTpw4MZm1aNGi4vPCxujvf/97Mjv44IOT2YIFC5JZTe8jjz/+eDLr1atX6bFQFyZPnpzMXn/99Q04SdNS9rN327ZtN9wgGyF3PAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZKJ4AAAAAyKK6vgdoTD772c8ms759+yazKVOmJLNbb701mX3ta19LZmWPgoyIOOOMM5LZzjvvnMxat26dzN54443Sa5Zp06ZNMit7XKjHWtJUrVixojT/0Y9+lMzefffduh4HNkpPPvlkMvu///u/ZLb99tuXnnfLLbeseCZoqsre937yk58ks//5n/9JZosWLUpmLVu2TGbXX399MouI2GuvvUpzoHE688wzk9n06dM34CQbH3c8AQAAAJCF4gkAAACALBRPAAAAAGSheAIAAAAgC8UTAAAAAFkongAAAADIorq+B2hMqqvTn65LLrkkmR166KHJ7LjjjktmZY967dOnTzKLiOjcuXMymzdvXumxldhmm21K87vvvjuZ9e7du67HoQl7//33k1nZo5MjIqqqqup6nFIffPBBMvvWt75Veuy4cePqepxSw4YN26DXgw1l9erVyez73/9+MmvRokUy++Mf/1h6zXbt2tU8GDQxS5cuLc0PPvjgZPbcc8/V9TjRunXrZHbXXXeVHluWb7nllsnsS1/6UjL77Gc/m8y6d+9eOg8bn6IoKsoqtWbNmtK8WbO6v1/lqKOOSmb/+7//m2WWGTNmJLPhw4cns3PPPTeZ7bjjjhXPszFxxxMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkUV3fAzQV/fv3T2aPPfZYMhs2bFgye/DBByvKIiKKokhmVVVVyezYY49NZp/97GeT2YgRI0rn6dy5c2kOtXX11Vcns7lz55Ye26xZumv/zne+k8xatGiRzK655ppk9te//jWZ3XHHHcksl/333z+ZDRkyZANOAhvOL37xi2RW9v584oknJrMePXqs10xQ31asWJHMfvvb3yazc889N5m98cYbpdcs+/4zh0WLFiWzW265Jcs1f/KTn1R03M4771yal32vUfYzCI3X888/n8yuvfbaZDZ27NhkNnPmzGS2xx57lM5z4IEHluYpw4cPT2a9evVKZmVfo3r37l16zdmzZ9c82DrccMMNyWzVqlXJrOz7jIjynyM2Ju54AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQRVVRFEVNH7RkyZLo0KFDLF68ONq3b78h5oJGozHsR2OYsbbKHsfcrJkuvbq6Opk999xzyaymRzk3ZQ19Pxr6fA3Be++9l8x69OiRzBYuXJjMHnnkkWRW6WOlqXuNYT/qa8ayx5GPHj06mV166aUVXa+mHynK3r8rtf/++yezXN8TPP7448ksx79jRMTIkSOT2RVXXJHlmhtKQ9/hhj7fv5s/f34yW7p0aTLr1KlT6Xk7dOhQ8Ux1bdasWaX5kCFDktnUqVMrumbZ17dFixaVHtuuXbuKrtlY1HZH/JQGAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACCL9HO3ARqgVq1aJbMPPvhgA05Sf5o3b57MfvGLXySznXfeOcc4UO9uvvnmZDZv3rxkduqppyazAw88cL1mgvpW9uj0n/70p3V+vX79+pXmX/rSl5JZ69atk9lRRx2VzLp161bzYHXsrbfeSmbjx4+vKNttt91KrzlixIiaB4OI2GyzzSrKGpPu3buX5j179kxmU6dOreiaHTp0SGZVVVUVnXNj444nAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZVNf3AACfxtVXX53Myh6NHhGxevXquh4nm4svvjiZ9e/fP5l5BDwbo9GjRyezZs3Sf8Z2ySWX5BgHGoTNN988mR100EHJbP78+cls2LBhyey0006r3WCNXLdu3ZLZhRdeWFEG1J3//u//Tma/+c1vKjrnk08+mczatm1b0Tk3Nu54AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQRXV9DwDwaZx00knJ7POf/3zpsbvuumsyW7FiRcUzpfTp0yeZlf17REQcc8wxycxjW6H2Pve5zyWzDh06bMBJoOG477776nsEgCx69OiRzFatWrUBJ+Gj3PEEAAAAQBaKJwAAAACyUDwBAAAAkIXiCQAAAIAsFE8AAAAAZKF4AgAAACCL6voeAKCulD0+NSJi2bJlG2gSYEM64ogjktm7776bzFauXJnMNtlkk/WaCQCAf3HHEwAAAABZKJ4AAAAAyELxBAAAAEAWiicAAAAAslA8AQAAAJCF4gkAAACALBRPAAAAAGRRXd8DAACsj7Fjx9b3CAAAJLjjCQAAAIAsFE8AAAAAZKF4AgAAACALxRMAAAAAWSieAAAAAMhC8QQAAABAFoonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZVNfmg4qiiIiIJUuWZB0GGqMP9+LDPWmI7DCkNfQdtr+Q1tD3N8IOQ5mGvsP2F8rVdodrVTwtXbo0IiK6d+++nmNB07V06dLo0KFDfY+xTnYYatZQd9j+Qs0a6v5G2GGojYa6w/YXaqemHa4qalEvr1mzJt56661o165dVFVV1emA0NgVRRFLly6Nbt26RbNmDfNvr9phSGvoO2x/Ia2h72+EHYYyDX2H7S+Uq+0O16p4AgAAAIBPq+HVygAAAAA0CYonAAAAALJQPAEAAACQheIJAAAAgCwUTwAAAABkoXgCAAAAIAvFEwAAAABZ/P8ARRPuN8KHSGYAAAAASUVORK5CYII=\n"},"metadata":{}}],"source":["fig, ax = plt.subplots(2,5, figsize=(15, 7))\n","ax = ax.flatten()\n","\n","for i, (image, label) in enumerate(zip(x_train[:10], y_train[:10])):\n","  img = image.permute(1, 2, 0)\n","  ax[i].imshow(img, cmap = \"Greys\")\n","  ax[i].set_title(f\"Label: {label}\",  fontsize=12)\n","  ax[i].set_xticks([])\n","  ax[i].set_yticks([])"]},{"cell_type":"markdown","metadata":{"id":"0C2oV_stsu7a"},"source":["#### Visualize the test data and labels"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1757610481284,"user":{"displayName":"Mujtaba Nazari","userId":"16194551095817193214"},"user_tz":300},"id":"oUE_2kgYsu7a","outputId":"272bf5af-d602-47bc-a539-8d1bb8fe1b38"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x700 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["fig, ax = plt.subplots(2,5, figsize=(15, 7))\n","ax = ax.flatten()\n","\n","for i, (image, label) in enumerate(zip(x_test[:10], y_test[:10])):\n","  img = image.permute(1, 2, 0)\n","  ax[i].imshow(img, cmap = \"Greys\")\n","  ax[i].set_title(f\"Label: {label}\",  fontsize=12)\n","  ax[i].set_xticks([])\n","  ax[i].set_yticks([])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}